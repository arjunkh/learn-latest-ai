{
  "content_hash": "9504c5b8c63c1100ba8bb674921ef60be77b231b5e8b74b28f35d3611599ecfa",
  "share_id": "ciaqfw",
  "title": "Cognitive Inception: Agentic Reasoning against Visual Deceptions by Injecting Skepticism",
  "optimized_headline": "\"How Agentic Reasoning Unveils Visual Deceptions Through Skepticism\"",
  "url": "https://arxiv.org/abs/2511.17672",
  "source": "ArXiv AI",
  "published_at": "2025-11-25T05:00:00.000Z",
  "raw_excerpt": "arXiv:2511.17672v1 Announce Type: new \nAbstract: As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by generated contents, and the reliability of reasoning processes is jeopardized. Therefore, facing rap",
  "raw_body": "arXiv:2511.17672v1 Announce Type: new \nAbstract: As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by generated contents, and the reliability of reasoning processes is jeopardized. Therefore, facing rapidly emerging generative models and diverse data distribution, it is of vital importance to improve LLMs' generalizable reasoning to verify the authenticity of visual inputs against potential deceptions. Inspired by human cognitive processes, we discovered that LLMs exhibit tendency of over-trusting the visual inputs, while injecting skepticism could significantly improve the models visual cognitive capability against visual deceptions. Based on this discovery, we propose \\textbf{Inception}, a fully reasoning-based agentic reasoning framework to conduct generalizable authenticity verification by injecting skepticism, where LLMs' reasoning logic is iteratively enhanced between External Skeptic and Internal Skeptic agents. To the best of our knowledge, this is the first fully reasoning-based framework against AIGC visual deceptions. Our approach achieved a large margin of performance improvement over the strongest existing LLM baselines and SOTA performance on AEGIS benchmark.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Recent research introduced a new framework called Inception that enhances how AI models differentiate between real and generated visuals. By injecting skepticism into the reasoning processes of multi-modal Large Language Models (LLMs), the framework significantly boosts their ability to identify visual deceptions. This approach outperformed existing models and achieved state-of-the-art results on the AEGIS benchmark. As AI-generated content becomes more prevalent, improving verification of visual authenticity is increasingly important.",
  "why_it_matters": [
    "This advancement could directly benefit developers and users of AI tools that rely on accurate visual content, reducing misinformation risks.",
    "On a broader scale, enhancing LLMs' reasoning capabilities signals a shift towards more reliable AI systems, which could impact various industries reliant on visual data."
  ],
  "lenses": {
    "eli12": "Think of LLMs like a friend who believes everything they see. The new Inception framework teaches these models to question what they see, improving their ability to tell real images from fake ones. This is crucial as AI-generated visuals become more common, helping everyday people trust the content they encounter online.",
    "pm": "For product managers and founders, the Inception framework addresses a critical user need: trust in AI-generated visuals. By improving LLMs' skepticism, products could offer more reliable outputs, reducing user frustration and enhancing overall satisfaction. This could lead to cost savings by minimizing the need for manual verification of visual content.",
    "engineer": "Technically, the Inception framework employs a dual-agent system, combining External Skeptic and Internal Skeptic agents to iteratively enhance reasoning logic. This approach has shown a significant performance boost over existing LLMs, achieving state-of-the-art results on the AEGIS benchmark. Such advancements could reshape how visual data is processed and verified in AI applications."
  },
  "hype_meter": 2,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-11-26T03:59:19.310Z",
  "updated_at": "2025-11-26T03:59:19.310Z",
  "processing_order": 1764129559313
}