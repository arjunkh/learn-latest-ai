{
  "content_hash": "50208f0b04b24559f87f2eb5c390a9310ad4c94ae02a1ae7117094973da3a1eb",
  "share_id": "ncrvu7",
  "title": "Nvidia’s Cosmos Reason 2 aims to bring reasoning VLMs into the physical world",
  "optimized_headline": "Nvidia's Cosmos Reason 2: Bridging AI Reasoning with Real-World Applications",
  "url": "https://venturebeat.com/orchestration/nvidias-cosmos-reason-2-aims-to-bring-reasoning-vlms-into-the-physical-world",
  "source": "VentureBeat",
  "published_at": "2026-01-05T20:00:00.000Z",
  "raw_excerpt": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.\nAt CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces ",
  "raw_body": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.\nAt CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.\nNvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.\nCosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.\nNvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.\nOther vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.\n“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”\nShe added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”\nMoving to physical agents\nBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”\n“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world's largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”\nThe company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. \nNvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. \nAdditions to the Nemotron family\nBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. \nNvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. \nIn a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. \nNemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. \n“Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. \nNemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Nvidia has unveiled Cosmos Reason 2, a vision-language model designed for embodied reasoning, at CES 2026. This model enhances AI agents' ability to plan actions in physical environments, building on its predecessor, Cosmos Reason 1. With the growing focus on physical AI, Nvidia aims to support the development of versatile robots that can navigate complex real-world tasks. This shift is significant as it marks a move towards more capable and adaptable AI systems in everyday life.",
  "why_it_matters": [
    "This development could immediately benefit industries using robotics, enabling more efficient and adaptable systems in tasks like manufacturing and logistics.",
    "On a broader level, this reflects a shift in the AI market towards integrating reasoning capabilities in physical agents, potentially transforming how we interact with technology."
  ],
  "lenses": {
    "eli12": "Nvidia’s new Cosmos Reason 2 helps robots think and plan actions in the real world, similar to how we plan our day. This means robots can do more complex tasks, making them more useful in various settings. As AI becomes more capable, it could change how we use technology in our daily lives.",
    "pm": "For product managers and founders, Cosmos Reason 2 signifies a growing user need for adaptable AI in physical environments. This could lead to more efficient processes in industries like logistics. Understanding this shift could help in developing products that leverage these advanced capabilities.",
    "engineer": "Technically, Cosmos Reason 2 builds on a two-dimensional ontology for embodied reasoning, enhancing the planning capabilities of AI agents. It competes with other models like Google’s PaliGemma but focuses on reasoning in physical spaces. This positions Nvidia's models as vital for developing generalist robots capable of complex tasks."
  },
  "hype_meter": 4,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2026-01-06T04:15:20.073Z",
  "updated_at": "2026-01-06T04:15:20.073Z",
  "processing_order": 1767672920074
}