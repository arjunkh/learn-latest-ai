{
  "content_hash": "6fafb4e2339a824a476f3900127df042a92dc6e1629f806ce1c921969ceeb61c",
  "share_id": "gnf80n",
  "title": "Google’s new framework helps AI agents spend their compute and tool budget more wisely",
  "optimized_headline": "Google's framework enables AI agents to optimize compute and tool usage.",
  "url": "https://venturebeat.com/ai/googles-new-framework-helps-ai-agents-spend-their-compute-and-tool-budget",
  "source": "VentureBeat",
  "published_at": "2025-12-12T00:00:00.000Z",
  "raw_excerpt": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents ex",
  "raw_body": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.\nAs AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.\nFor enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.\nThe challenge of scaling tool use\nTraditional test-time scaling focuses on letting models \"think\" longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.\nThis introduces significant operational overhead for businesses. \"Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,\" Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. \"Tool calls themselves introduce additional API costs.\"\nThe researchers found that simply granting agents more test-time resources does not guarantee better performance. \"In a deep research task, if the agent has no sense of budget, it often goes down blindly,\" Wang and Liu explained. \"It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.\"\nOptimizing resources with Budget Tracker\nTo evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called \"Budget Tracker.\" This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.\nThe team hypothesized that \"providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.\"\nBudget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)\nIn Google's implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.\nTo test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.\nThey tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as Gemini 2.5 Pro, Gemini 2.5 Flash, and Claude Sonnet 4. The experiments show that this simple plug-in improves performance across various budget constraints.\n\"Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,\" the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.\nBATS: A comprehensive framework for budget-aware scaling\nTo further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent's behavior as it formulates its response.\nBATS uses multiple modules to orchestrate the agent's actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to \"dig deeper\" into a promising lead or \"pivot\" to alternative paths based on resource availability.\nGiven an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.\nThe iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.\nThe researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.\nBATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.\nAccording to the authors, this efficiency makes previously expensive workflows viable. \"This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,\" they said.\nAs enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.\n\"We believe the relationship between reasoning and economics will become inseparable,\" Wang and Liu said. \"In the future, [models] must reason about value.\"",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Researchers at Google and UC Santa Barbara have introduced a new framework for AI agents to manage their tool and compute budgets more efficiently. This includes the 'Budget Tracker,' which improves tool use by 31.3% while reducing search calls by 40.4%. Another technique, called 'Budget Aware Test-time Scaling' (BATS), enhances performance under budget constraints, achieving 24.6% accuracy on the BrowseComp dataset. This development is crucial as enterprises seek to deploy cost-effective AI solutions.",
  "why_it_matters": [
    "This framework could significantly reduce operational costs for businesses that rely on AI agents, making them more feasible for various applications.",
    "On a broader scale, it reflects a shift towards more sustainable AI practices, where balancing performance and cost becomes essential in enterprise settings."
  ],
  "lenses": {
    "eli12": "Google's new AI framework helps agents use their resources better, like a budget planner for spending wisely. It shows agents how much they have left to use, which can prevent waste. This matters for everyday people because it could lead to more efficient AI tools that save money and time in various applications.",
    "pm": "For product managers and founders, this framework addresses a crucial user need: efficient resource management. By reducing costs and improving performance, it allows for more scalable AI deployments. The practical implication is that businesses can develop AI solutions that are not only effective but also economically viable.",
    "engineer": "The new framework introduces two key techniques: Budget Tracker and BATS, which optimize resource allocation for AI agents. Budget Tracker allows agents to adjust their strategies based on real-time budget signals, while BATS dynamically adapts agent behavior to maximize performance under budget constraints. Experiments show BATS achieved 24.6% accuracy on BrowseComp with fewer tool calls compared to standard methods, highlighting its efficiency."
  },
  "hype_meter": 4,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-12-13T04:01:07.336Z",
  "updated_at": "2025-12-13T04:01:07.336Z",
  "processing_order": 1765598467337
}