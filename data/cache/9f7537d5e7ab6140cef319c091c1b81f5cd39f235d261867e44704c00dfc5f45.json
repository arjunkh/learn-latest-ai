{
  "content_hash": "9f7537d5e7ab6140cef319c091c1b81f5cd39f235d261867e44704c00dfc5f45",
  "share_id": "tpei6t",
  "title": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization",
  "optimized_headline": "Unlocking Tailored Health Simulations: A New Framework for Stakeholder Insights",
  "url": "https://arxiv.org/abs/2509.04646",
  "source": "ArXiv AI",
  "published_at": "2025-09-08T04:00:00.000Z",
  "raw_excerpt": "arXiv:2509.04646v1 Announce Type: new \nAbstract: Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behaviors and physical activity behaviors. These models are potentially usable by different stakeholder groups, ",
  "raw_body": "arXiv:2509.04646v1 Announce Type: new \nAbstract: Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behaviors and physical activity behaviors. These models are potentially usable by different stakeholder groups, as they support policy-makers to estimate the consequences of potential interventions and they can guide individuals in making healthy choices in complex environments. However, this potential may not be fully realized because of the models' complexity, which makes them inaccessible to the stakeholders who could benefit the most. While Large Language Models (LLMs) can translate simulation outputs and the design of models into text, current approaches typically rely on one-size-fits-all summaries that fail to reflect the varied informational needs and stylistic preferences of clinicians, policymakers, patients, caregivers, and health advocates. This limitation stems from a fundamental gap: we lack a systematic understanding of what these stakeholders need from explanations and how to tailor them accordingly. To address this gap, we present a step-by-step framework to identify stakeholder needs and guide LLMs in generating tailored explanations of health simulations. Our procedure uses a mixed-methods design by first eliciting the explanation needs and stylistic preferences of diverse health stakeholders, then optimizing the ability of LLMs to generate tailored outputs (e.g., via controllable attribute tuning), and then evaluating through a comprehensive range of metrics to further improve the tailored generation of summaries.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "A new framework aims to improve how health simulations communicate complex data to various stakeholders. By addressing the specific needs of groups like policymakers and patients, it seeks to make insights from models more accessible. Current summaries often fail to meet these diverse needs, limiting their usefulness. This initiative is crucial now as it could enhance decision-making in health by providing clearer, more relevant information.",
  "why_it_matters": [
    "Health policymakers could make better-informed decisions by receiving tailored insights from simulations, leading to more effective interventions.",
    "This approach signals a shift towards personalized communication in healthcare, recognizing that different stakeholders require different information to act effectively."
  ],
  "lenses": {
    "eli12": "Imagine trying to read a book in a language you don't understand. This new framework helps translate complex health simulation data into clear, personalized summaries for various audiences. It matters because better communication can lead to healthier choices and improved public health outcomes.",
    "pm": "For product managers and founders, this framework highlights the importance of understanding user needs in health tech. Tailored insights could improve user engagement and decision-making, potentially reducing costs by streamlining information delivery for different stakeholders.",
    "engineer": "This framework combines stakeholder analysis with Large Language Models to generate customized explanations of health simulations. By using controllable attribute tuning, it aims to enhance the relevance of summaries for diverse users. This could lead to more effective communication of complex data, though the implementation of such tailored outputs may require significant technical refinement."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-09-09T03:47:44.169Z",
  "updated_at": "2025-09-09T03:47:44.169Z",
  "processing_order": 1757389664171
}