{
  "content_hash": "f252904888c95446560701f944a3ea43bfbd0d9371f6af40e45f67d45cfa3c34",
  "share_id": "tmdu9o",
  "title": "The missing data link in enterprise AI: Why agents need streaming context, not just better prompts",
  "optimized_headline": "Why Enterprise AI Agents Require Streaming Context Over Enhanced Prompts",
  "url": "https://venturebeat.com/data-infrastructure/the-missing-data-link-in-enterprise-ai-why-agents-need-streaming-context-not",
  "source": "VentureBeat",
  "published_at": "2025-10-29T15:00:00.000Z",
  "raw_excerpt": "Enterprise AI agents today face a fundamental timing problem: They can't easily act on critical business events because they aren't always aware of them in real-time.\nThe challenge is infrastructure. Most enterprise data lives in databases fed by extract-transform-load (ETL) jobs that run hourly or daily — ultimately too slow for agents that must respond in real time.\nOne potential way to tackle t",
  "raw_body": "Enterprise AI agents today face a fundamental timing problem: They can't easily act on critical business events because they aren't always aware of them in real-time.\nThe challenge is infrastructure. Most enterprise data lives in databases fed by extract-transform-load (ETL) jobs that run hourly or daily — ultimately too slow for agents that must respond in real time.\nOne potential way to tackle that challenge is to have agents directly interface with streaming data systems. Among the primary approaches in use today are the open source Apache Kafka and Apache Flink technologies. There are multiple commercial implementations based on those technologies, too, Confluent, which is led by the original creators behind Kafka, being one of them.\nToday, Confluent is introducing a real-time context engine designed to solve this latency problem. The technology builds on Apache Kafka, the distributed event streaming platform that captures data as events occur, and open-source Apache Flink, the stream processing engine that transforms those events in real time.\nThe company is also releasing an open-source framework, Flink Agents, developed in collaboration with Alibaba Cloud, LinkedIn and Ververica. The framework brings event-driven AI agent capabilities directly to Apache Flink, allowing organizations to build agents that monitor data streams and trigger automatically based on conditions without committing to Confluent's managed platform.\n\"Today, most enterprise AI systems can't respond automatically to important events in a business without someone prompting them first,\" Sean Falconer, Confluent's head of AI, told VentureBeat. \"This leads to lost revenue, unhappy customers or added risk when a payment fails or a network malfunctions.\"\nThe significance extends beyond Confluent's specific products. The industry is recognizing that AI agents require different data infrastructure than traditional applications. Agents don't just retrieve information when asked. They need to observe continuous streams of business events and act automatically when conditions warrant. This requires streaming architecture, not batch pipelines.\nBatch versus streaming: Why RAG alone isn't enough\nTo understand the problem, it's important to distinguish between the different approaches to moving data through enterprise systems and how they can connect to agentic AI.\nIn batch processing, data accumulates in source systems until a scheduled job runs. That job extracts the data, transforms it and loads it into a target database or data warehouse. This might occur hourly, daily or even weekly. The approach works well for analytical workloads, but it creates latency between when something happens in the business and when systems can act on it.\nData streaming inverts this model. Instead of waiting for scheduled jobs, streaming platforms like Apache Kafka capture events as they occur. Each database update, user action, transaction or sensor reading becomes an event published to a stream. Apache Flink then processes these streams to join, filter and aggregate data in real time. The result is processed data that reflects the current state of the business, updating continuously as new events arrive.\nThis distinction becomes critical when you consider what kinds of context AI agents actually need. Much of the current enterprise AI discussion focuses on retrieval-augmented generation (RAG), which handles semantic search over knowledge bases to find relevant documentation, policies or historical information. RAG works well for questions like \"What's our refund policy?\" where the answer exists in static documents.\nBut many enterprise use cases require what Falconer calls \"structural context\" — precise, up-to-date information from multiple operational systems stitched together in real time. Consider a job recommendation agent that requires user profile data from the HR database, browsing behavior from the last hour, search queries from minutes ago and current open positions across multiple systems.\n\"The part that we're unlocking for businesses is the ability to essentially serve that structural context needed to deliver the freshest version,\" Falconer said.\nThe MCP connection problem: Stale data and fragmented context\nThe challenge isn't simply connecting AI to enterprise data. Model Context Protocol (MCP), introduced by Anthropic earlier this year, already standardized how agents access data sources. The problem is what happens after the connection is made.\nIn most enterprise architectures today, AI agents connect via MCP to data lakes or warehouses fed by batch ETL pipelines. This creates two critical failures: The data is stale, reflecting yesterday's reality rather than current events, and it's fragmented across multiple systems, requiring significant preprocessing before an agent can reason about it effectively.\nThe alternative — putting MCP servers directly in front of operational databases and APIs — creates different problems. Those endpoints weren't designed for agent consumption, which can lead to high token costs as agents process excessive raw data and multiple inference loops as they try to make sense of unstructured responses.\n\"Enterprises have the data, but it's often stale, fragmented or locked in formats that AI can't use effectively,\" Falconer explained. \"The real-time context engine solves this by unifying data processing, reprocessing and serving, turning continuous data streams into live context for smarter, faster and more reliable AI decisions.\"\nThe technical architecture: Three layers for real-time agent context\nConfluent's platform encompasses three elements that work together or adopted separately.\nThe real-time context engine is the managed data infrastructure layer on Confluent Cloud. Connectors pull data into Kafka topics as events occur. Flink jobs process these streams into \"derived datasets\" — materialized views joining historical and real-time signals. For customer support, this might combine account history, current session behavior and inventory status into one unified context object. The Engine exposes this through a managed MCP server.\nStreaming agents is Confluent's proprietary framework for building AI agents that run natively on Flink. These agents monitor data streams and trigger automatically based on conditions — they don't wait for prompts. The framework includes simplified agent definitions, built-in observability and native Claude integration from Anthropic. It's available in open preview on Confluent's platform.\nFlink Agents is the open-source framework developed with Alibaba Cloud, LinkedIn and Ververica. It brings event-driven agent capabilities directly to Apache Flink, allowing organizations to build streaming agents without committing to Confluent's managed platform. They handle operational complexity themselves but avoid vendor lock-in.\nCompetition heats up for agent-ready data infrastructure\nConfluent isn't alone in recognizing that AI agents need different data infrastructure. \nThe day before Confluent's announcement, rival Redpanda introduced its own Agentic Data Plane — combining streaming, SQL and governance specifically for AI agents. Redpanda acquired Oxla's distributed SQL engine to give agents standard SQL endpoints for querying data in motion or at rest. The platform emphasizes MCP-aware connectivity, full observability of agent interactions and what it calls \"agentic access control\" with fine-grained, short-lived tokens.\nThe architectural approaches differ. Confluent emphasizes stream processing with Flink to create derived datasets optimized for agents. Redpanda emphasizes federated SQL querying across disparate sources. Both recognize agents need real-time context with governance and observability.\nBeyond direct streaming competitors, Databricks and Snowflake are fundamentally analytical platforms adding streaming capabilities. Their strength is complex queries over large datasets, with streaming as an enhancement. Confluent and Redpanda invert this: Streaming is the foundation, with analytical and AI workloads built on top of data in motion.\nHow streaming context works in practice\nAmong the users of Confluent's system is transportation vendor Busie. The company is building a modern operating system for charter bus companies that helps them manage quotes, trips, payments and drivers in real time. \n\"Data streaming is what makes that possible,\" Louis Bookoff, Busie co-founder and CEO told VentureBeat. \"Using Confluent, we move data instantly between different parts of our system instead of waiting for overnight updates or batch reports. That keeps everything in sync and helps us ship new features faster.\nBookoff noted that the same foundation is what will make gen AI valuable for his customers.\n\"In our case, every action like a quote sent or a driver assigned becomes an event that streams through the system immediately,\" Bookoff said. \"That live feed of information is what will let our AI tools respond in real time with low latency rather than just summarize what already happened.\"\nThe challenge, however, is how to understand context. When thousands of live events flow through the system every minute, AI models need relevant, accurate data without getting overwhelmed.\n \"If the data isn't grounded in what is happening in the real world, AI can easily make wrong assumptions and in turn take wrong actions,\" Bookoff said. \"Stream processing solves that by continuously validating and reconciling live data against activity in Busie.\"\nWhat this means for enterprise AI strategy\nStreaming context architecture signals a fundamental shift in how AI agents consume enterprise data. \nAI agents require continuous context that blends historical understanding with real-time awareness — they need to know what happened, what's happening and what might happen next, all at once.\nFor enterprises evaluating this approach, start by identifying use cases where data staleness breaks the agent. Fraud detection, anomaly investigation and real-time customer intervention fail with batch pipelines that refresh hourly or daily.  If your agents need to act on events within seconds or minutes of them occurring, streaming context becomes necessary rather than optional.\n\"When you're building applications on top of foundation models, because they're inherently probabilistic, you use data and context to steer the model in a direction where you want to get some kind of outcome,\" Falconer said. \"The better you can do that, the more reliable and better the outcome.\"",
  "category": "trends_risks_outlook",
  "category_confidence": "medium",
  "speedrun": "Enterprise AI agents struggle with real-time responsiveness due to outdated data infrastructure, relying on batch processing that lags behind business events. Confluent is addressing this with a new real-time context engine built on Apache Kafka and Flink, enabling agents to act automatically based on live data streams. This shift is crucial as businesses need AI agents that can respond instantly to critical events, reducing risks and improving customer satisfaction.",
  "why_it_matters": [
    "Businesses relying on AI agents could see immediate improvements in responsiveness, minimizing lost revenue and customer dissatisfaction. This is achieved by enabling agents to act on real-time data rather than waiting for batch updates.",
    "The introduction of real-time context architecture indicates a broader industry shift towards infrastructure that supports continuous data flow, enhancing AI capabilities across various sectors."
  ],
  "lenses": {
    "eli12": "Imagine trying to catch a bus that only arrives every hour. If you miss it, you wait. This is like current AI agents that rely on outdated data. Confluent's new system allows agents to act on real-time data, making them much more responsive. This is important for everyday people because it means quicker service and fewer errors in areas like customer support.",
    "pm": "For product managers and founders, this development highlights the need for AI solutions that can act on real-time data. By integrating streaming data, companies could enhance user experience and reduce operational costs. This means that products can evolve faster, reacting to user actions without delays.",
    "engineer": "From a technical perspective, Confluent's new real-time context engine utilizes Apache Kafka for event streaming and Apache Flink for processing these streams. This architecture allows for the creation of derived datasets that combine real-time and historical data, enabling AI agents to operate more effectively. However, engineers must ensure that the system can handle high volumes of data without overwhelming the AI models."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-10-30T03:56:03.993Z",
  "updated_at": "2025-10-30T03:56:03.993Z",
  "processing_order": 1761796563995
}