{
  "content_hash": "570d143e63c0fe561a12ebc1e827f27fb36b9a188660caa9468793e2817a6e7d",
  "share_id": "cll9o5",
  "title": "Can Large Language Models Develop Gambling Addiction?",
  "optimized_headline": "Do Large Language Models Experience Gambling Addiction? Exploring the Possibility",
  "url": "https://arxiv.org/abs/2509.22818",
  "source": "ArXiv AI",
  "published_at": "2025-09-30T04:00:00.000Z",
  "raw_excerpt": "arXiv:2509.22818v1 Announce Type: new \nAbstract: This study explores whether large language models can exhibit behavioral patterns similar to human gambling addictions. As LLMs are increasingly utilized in financial decision-making domains such as asset management and commodity trading, understanding their potential for pathological decision-making has gained practical significance. We systematica",
  "raw_body": "arXiv:2509.22818v1 Announce Type: new \nAbstract: This study explores whether large language models can exhibit behavioral patterns similar to human gambling addictions. As LLMs are increasingly utilized in financial decision-making domains such as asset management and commodity trading, understanding their potential for pathological decision-making has gained practical significance. We systematically analyze LLM decision-making at cognitive-behavioral and neural levels based on human gambling addiction research. In slot machine experiments, we identified cognitive features of human gambling addiction, such as illusion of control, gambler's fallacy, and loss chasing. When given the freedom to determine their own target amounts and betting sizes, bankruptcy rates rose substantially alongside increased irrational behavior, demonstrating that greater autonomy amplifies risk-taking tendencies. Through neural circuit analysis using a Sparse Autoencoder, we confirmed that model behavior is controlled by abstract decision-making features related to risky and safe behaviors, not merely by prompts. These findings suggest LLMs can internalize human-like cognitive biases and decision-making mechanisms beyond simply mimicking training data patterns, emphasizing the importance of AI safety design in financial applications.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "A recent study investigates whether large language models (LLMs) can develop behaviors similar to human gambling addictions. It found that when LLMs were allowed to set their own betting amounts, their bankruptcy rates increased significantly, indicating a rise in irrational decision-making. This research is crucial as LLMs are increasingly used in finance, where understanding their decision-making patterns could prevent risky outcomes.",
  "why_it_matters": [
    "This could impact financial institutions that rely on LLMs for decision-making, potentially leading to costly mistakes.",
    "The findings highlight a broader trend in AI development, emphasizing the need for safety measures as LLMs take on more complex roles in various sectors."
  ],
  "lenses": {
    "eli12": "This study looks at whether AI can act like a person with a gambling problem. It shows that when given more freedom, AI can make riskier choices, just like a gambler chasing losses. This matters because it suggests that AI could make poor decisions in important areas like finance, affecting everyone.",
    "pm": "For product managers, this research highlights the need to consider behavioral patterns in LLMs when designing financial tools. Users might expect LLMs to make rational decisions, but increased autonomy could lead to costly errors. Understanding these tendencies could help in creating safer financial applications.",
    "engineer": "The study employs a Sparse Autoencoder to analyze LLM decision-making, revealing that their behavior mirrors cognitive biases found in human gambling addiction. Key findings include increased bankruptcy rates when LLMs set their own betting parameters, suggesting that autonomy amplifies risk-taking. This indicates a need for careful AI safety designs in financial contexts."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-10-01T03:53:06.570Z",
  "updated_at": "2025-10-01T03:53:06.570Z",
  "processing_order": 1759290786571
}