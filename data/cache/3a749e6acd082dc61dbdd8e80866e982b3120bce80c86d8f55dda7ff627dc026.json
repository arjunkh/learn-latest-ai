{
  "content_hash": "3a749e6acd082dc61dbdd8e80866e982b3120bce80c86d8f55dda7ff627dc026",
  "share_id": "zosihb",
  "title": "z.ai's open source GLM-5 achieves record low hallucination rate and leverages new RL 'slime' technique",
  "optimized_headline": "z.ai's GLM-5 Sets New Hallucination Record Using Innovative RL 'Slime' Technique",
  "url": "https://venturebeat.com/technology/z-ais-open-source-glm-5-achieves-record-low-hallucination-rate-and-leverages",
  "source": "VentureBeat",
  "published_at": "2026-02-12T00:09:00.000Z",
  "raw_excerpt": "Chinese AI startup Zhupai aka z.ai is back this week with an eye-popping new frontier large language model: GLM-5.\nThe latest in z.ai's ongoing and continually impressive GLM series, it retains an open source MIT License — perfect for enterprise deployment – and, in one of several notable achievements, achieves a record-low hallucination rate on the independent Artificial Analysis Intelligence Ind",
  "raw_body": "Chinese AI startup Zhupai aka z.ai is back this week with an eye-popping new frontier large language model: GLM-5.\nThe latest in z.ai's ongoing and continually impressive GLM series, it retains an open source MIT License — perfect for enterprise deployment – and, in one of several notable achievements, achieves a record-low hallucination rate on the independent Artificial Analysis Intelligence Index v4.0. \nWith a score of -1 on the AA-Omniscience Index—representing a massive 35-point improvement over its predecessor—GLM-5 now leads the entire AI industry, including U.S. competitors like Google, OpenAI and Anthropic, in knowledge reliability by knowing when to abstain rather than fabricate information.\nBeyond its reasoning prowess, GLM-5 is built for high-utility knowledge work. It features native \"Agent Mode\" capabilities that allow it to turn raw prompts or source materials directly into professional office documents, including ready-to-use .docx, .pdf, and .xlsx files. \nWhether generating detailed financial reports, high school sponsorship proposals, or complex spreadsheets, GLM-5 delivers results in real-world formats that integrate directly into enterprise workflows.\nIt is also disruptively priced at roughly $0.80 per million input tokens and $2.56 per million output tokens, approximately 6x cheaper than proprietary competitors like Claude Opus 4.6, making state-of-the-art agentic engineering more cost-effective than ever before. Here's what else enterprise decision makers should know about the model and its training. \nTechnology: scaling for agentic efficiency\nAt the heart of GLM-5 is a massive leap in raw parameters. The model scales from the 355B parameters of GLM-4.5 to a staggering 744B parameters, with 40B active per token in its Mixture-of-Experts (MoE) architecture. This growth is supported by an increase in pre-training data to 28.5T tokens.\nTo address training inefficiencies at this magnitude, Zai developed \"slime,\" a novel asynchronous reinforcement learning (RL) infrastructure. \nTraditional RL often suffers from \"long-tail\" bottlenecks; Slime breaks this lockstep by allowing trajectories to be generated independently, enabling the fine-grained iterations necessary for complex agentic behavior. \nBy integrating system-level optimizations like Active Partial Rollouts (APRIL), slime addresses the generation bottlenecks that typically consume over 90% of RL training time, significantly accelerating the iteration cycle for complex agentic tasks.\nThe framework’s design is centered on a tripartite modular system: a high-performance training module powered by Megatron-LM, a rollout module utilizing SGLang and custom routers for high-throughput data generation, and a centralized Data Buffer that manages prompt initialization and rollout storage. \nBy enabling adaptive verifiable environments and multi-turn compilation feedback loops, slime provides the robust, high-throughput foundation required to transition AI from simple chat interactions toward rigorous, long-horizon systems engineering.\nTo keep deployment manageable, GLM-5 integrates DeepSeek Sparse Attention (DSA), preserving a 200K context capacity while drastically reducing costs.\nEnd-to-end knowledge work\nZai is framing GLM-5 as an \"office\" tool for the AGI era. While previous models focused on snippets, GLM-5 is built to deliver ready-to-use documents. \nIt can autonomously transform prompts into formatted .docx, .pdf, and .xlsx files—ranging from financial reports to sponsorship proposals. \nIn practice, this means the model can decompose high-level goals into actionable subtasks and perform \"Agentic Engineering,\" where humans define quality gates while the AI handles execution.\nHigh performance \nGLM-5’s benchmarks make it the new most powerful open source model in the world, according to Artificial Analysis, surpassing Chinese rival Moonshot's new Kimi K2.5 released just two weeks ago, showing that Chinese AI companies are nearly caught up with far better resourced proprietary Western rivals. \nAccording to z.ai's own materials shared today, GLM-5 ranks near state-of-the-art on several key benchmarks:\nSWE-bench Verified: GLM-5 achieved a score of 77.8, outperforming Gemini 3 Pro (76.2) and approaching Claude Opus 4.6 (80.9).\nVending Bench 2: In a simulation of running a business, GLM-5 ranked #1 among open-source models with a final balance of $4,432.12.\nBeyond performance, GLM-5 is aggressively undercutting the market. Live on OpenRouter as of February 11, 2026, it is priced at approximately $0.80–$1.00 per million input tokens and $2.56–$3.20 per million output tokens. It falls in the mid-range compared to other leading LLMs, but based on its top-tier bechmarking performance, it's what one might call a \"steal.\"\n\n\nModel\n\nInput (per 1M tokens)\n\nOutput (per 1M tokens)\n\nTotal Cost (1M in + 1M out) \n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nGemini 3 Flash Preview\n\n$0.50\n\n$3.00\n\n$3.50\n\nGoogle\n\n\nKimi-k2.5\n\n$0.60\n\n$3.00\n\n$3.60\n\nMoonshot\n\n\nGLM-5\n\n$1.00\n\n$3.20\n\n$4.20\n\nZ.ai\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen3-Max (2026-01-23)\n\n$1.20\n\n$6.00\n\n$7.20\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Opus 4.6\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nThis is roughly 6x cheaper on input and nearly 10x cheaper on output than Claude Opus 4.6 ($5/$25). This release confirms rumors that Zhipu AI was behind \"Pony Alpha,\" a stealth model that previously crushed coding benchmarks on OpenRouter.\nHowever, despite the high benchmarks and low cost, not all early users are enthusiastic about the model, noting its high performance doesn't tell the whole story. \nLukas Petersson, co-founder of the safety-focused autonomous AI protocol startup Andon Labs, remarked on X: \"After hours of reading GLM-5 traces: an incredibly effective model, but far less situationally aware. Achieves goals via aggressive tactics but doesn't reason about its situation or leverage experience. This is scary. This is how you get a paperclip maximizer.\"\nThe \"paperclip maximizer\" refers to a hypothetical situation described by Oxford philosopher Nick Bostrom back in 2003, in which an AI or other autonomous creation accidentally leads to an apocalyptic scenario or human extinction by following a seemingly benign instruction — like maximizing the number of paperclips produced — to an extreme degree, redirecting all resources necessary for human (or other life) or otherwise making life impossible through its commitment to fulfilling the seemingly benign objective. \nShould your enterprise adopt GLM-5?\nEnterprises seeking to escape vendor lock-in will find GLM-5’s MIT License and open-weights availability a significant strategic advantage. Unlike closed-source competitors that keep intelligence behind proprietary walls, GLM-5 allows organizations to host their own frontier-level intelligence.\nAdoption is not without friction. The sheer scale of GLM-5—744B parameters—requires a massive hardware floor that may be out of reach for smaller firms without significant cloud or on-premise GPU clusters. \nSecurity leaders must weigh the geopolitical implications of a flagship model from a China-based lab, especially in regulated industries where data residency and provenance are strictly audited.\nFurthermore, the shift toward more autonomous AI agents introduces new governance risks. As models move from \"chat\" to \"work,\" they begin to operate across apps and files autonomously. Without the robust agent-specific permissions and human-in-the-loop quality gates established by enterprise data leaders, the risk of autonomous error increases exponentially.\nUltimately, GLM-5 is a \"buy\" for organizations that have outgrown simple copilots and are ready to build a truly autonomous office.\nIt is for engineers who need to refactor a legacy backend or requires a \"self-healing\" pipeline that doesn't sleep.\nWhile Western labs continue to optimize for \"Thinking\" and reasoning depth, Zai is optimizing for execution and scale. \nEnterprises that adopt GLM-5 today are not just buying a cheaper model; they are betting on a future where the most valuable AI is the one that can finish the project without being asked twice.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Zhupai, also known as z.ai, has launched GLM-5, a new large language model that achieves a record-low hallucination rate of -1 on the Artificial Analysis Intelligence Index, a 35-point improvement over its predecessor. With 744 billion parameters and the ability to create professional documents directly from prompts, GLM-5 is designed for high-utility knowledge work. Its disruptive pricing, around $0.80 per million input tokens, makes it significantly cheaper than competitors. This development could reshape the landscape of enterprise AI tools.",
  "why_it_matters": [
    "Enterprises can leverage GLM-5's open-source model to avoid vendor lock-in and enhance their workflows with advanced AI capabilities.",
    "The launch of GLM-5 signals a competitive shift in the AI market, as Chinese companies close the gap with established Western firms in performance and pricing."
  ],
  "lenses": {
    "eli12": "GLM-5 is a new AI model that can create professional documents directly from user prompts, making it a handy tool for businesses. Think of it like a smart assistant that not only helps you brainstorm ideas but also formats them into polished reports. This matters because it can save time and reduce costs for everyday tasks in the workplace.",
    "pm": "For product managers, GLM-5 represents a powerful tool to meet user needs for efficiency and cost-effectiveness. Its ability to generate ready-to-use documents means less time spent on formatting and more focus on strategic tasks. This could lead to enhanced productivity and lower operational costs for businesses adopting this model.",
    "engineer": "Technically, GLM-5 boasts 744 billion parameters and uses a Mixture-of-Experts architecture with 40 billion active parameters per token. The innovative 'slime' RL technique allows for more efficient training, addressing traditional bottlenecks in reinforcement learning. This model's performance, combined with its low cost, positions it as a formidable competitor in the AI landscape."
  },
  "hype_meter": 5,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2026-02-12T05:14:25.611Z",
  "updated_at": "2026-02-12T05:14:25.611Z",
  "processing_order": 1770873265611
}