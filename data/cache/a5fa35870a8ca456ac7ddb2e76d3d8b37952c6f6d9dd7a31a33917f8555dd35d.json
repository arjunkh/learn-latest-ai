{
  "content_hash": "a5fa35870a8ca456ac7ddb2e76d3d8b37952c6f6d9dd7a31a33917f8555dd35d",
  "share_id": "aewcwv",
  "title": "AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI",
  "optimized_headline": "Exploring Korean Socio-Cultural Datasets: Uncovering Generative AI Risks with AssurAI",
  "url": "https://arxiv.org/abs/2511.20686",
  "source": "ArXiv AI",
  "published_at": "2025-11-27T05:00:00.000Z",
  "raw_excerpt": "arXiv:2511.20686v1 Announce Type: new \nAbstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Kore",
  "raw_body": "arXiv:2511.20686v1 Announce Type: new \nAbstract: The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "AssurAI is a new multimodal dataset designed to evaluate the safety of generative AI within the Korean socio-cultural context. It includes 11,480 instances across text, images, videos, and audio, addressing a gap in English-centric safety evaluations. The dataset defines 35 distinct AI risk factors tailored to Korean culture and has undergone rigorous quality control. This initiative is crucial now as it aims to enhance the safety of AI technologies for non-English speaking communities.",
  "why_it_matters": [
    "Korean developers and researchers can now better assess AI risks specific to their cultural context, improving safety measures.",
    "This project reflects a broader trend towards inclusive AI safety evaluations, recognizing the need for diverse datasets in global AI development."
  ],
  "lenses": {
    "eli12": "AssurAI is like creating a safety manual specifically for a new toy that kids in Korea will play with. By focusing on local risks and needs, it helps ensure that the AI is safe and reliable for everyone. This matters because it shows that safety in technology should consider cultural differences, making it relevant for everyday users.",
    "pm": "For product managers and founders, AssurAI highlights a growing user need for culturally relevant AI safety assessments. By integrating this dataset, products can be designed with a deeper understanding of local risks, potentially reducing costs associated with safety failures. It also opens up opportunities for creating tailored solutions that resonate with users in specific markets.",
    "engineer": "From a technical perspective, AssurAI introduces a comprehensive dataset that includes 11,480 instances across various modalities, which is a significant resource for training and evaluating AI systems. The dataset's development involved a two-phase construction process with expert input and crowdsourced scaling, ensuring high data integrity. This rigorous approach could enhance the performance of generative AI models, particularly in understanding socio-cultural nuances."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-11-28T03:55:41.662Z",
  "updated_at": "2025-11-28T03:55:41.662Z",
  "processing_order": 1764302141663
}