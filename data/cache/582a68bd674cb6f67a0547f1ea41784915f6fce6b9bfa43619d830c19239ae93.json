{
  "content_hash": "582a68bd674cb6f67a0547f1ea41784915f6fce6b9bfa43619d830c19239ae93",
  "share_id": "qndfxn",
  "title": "Qwen's new Deep Research update lets you turn its reports into webpages, podcasts in seconds",
  "optimized_headline": "Qwen's Deep Research update transforms reports into webpages and podcasts instantly.",
  "url": "https://venturebeat.com/ai/qwens-new-deep-research-update-lets-you-turn-its-reports-into-webpages",
  "source": "VentureBeat",
  "published_at": "2025-10-21T18:32:00.000Z",
  "raw_excerpt": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).\nThe update lets users generate not only comprehensive research reports with well-organized citations, but also inte",
  "raw_body": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).\nThe update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.\nThis functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. \nWhile the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. \nThis means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.\nThe update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:\n\n“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”\n\nMulti-Format Research Output\nThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.\nA demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. \nIn it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.\nOnce the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.\nThen, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\n\n\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\n\n\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.\n\nThis enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.\nThe website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. \nThe podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn't able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. \nThere was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I've used.\nHere's an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. \nWhile the website is hosted via a public link, the podcast must be downloaded by the user and can't be linked to publicly, from what I could tell in my brief usage so far.\nNote the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. \nThe web page versions of the report also include new graphics not found in the PDF report.\nComparisons to Google's NotebookLM\nWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.\nAI commentator and newsletter writer Chubby (@kimmonismus) noted on X:\n\n“I am really grateful that Qwen provides regular updates. That’s great.\n\nBut the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”\n\nWhile NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. \nThe comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.\nAvailability\nQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.\nNo pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.\nWhat's Next For Qwen Deep Research?\nBy combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. \nThe integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.\nStill, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.\nFor now, Qwen is signaling that research doesn’t end with a document — it begins with one.\nLet me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Alibaba's Qwen Team has launched a significant update to its Qwen Deep Research tool, allowing users to create research reports, web pages, and podcasts in just a few clicks. This update integrates features from Qwen3-Coder, Qwen-Image, and Qwen3-TTS, providing a seamless workflow without the need for additional setup. The tool's ability to generate multi-format outputs could change how research is shared and consumed, making it especially useful for content creators and educators.",
  "why_it_matters": [
    "Content creators can quickly turn research into various formats, enhancing accessibility and engagement. This could streamline workflows and save time.",
    "The update signifies a broader trend toward integrated AI tools that simplify content creation, potentially reshaping the research landscape and user expectations."
  ],
  "lenses": {
    "eli12": "Qwen's new update makes it easy to turn research into reports, web pages, and podcasts with just a few clicks. It's like having a personal assistant that can create different forms of content from a single idea. This matters because it allows everyone, from students to professionals, to share information in more engaging ways.",
    "pm": "For product managers and founders, this update highlights the need for tools that meet diverse user needs efficiently. By enabling quick content transformation, it could reduce costs associated with content creation and improve user satisfaction. Teams could focus more on research quality rather than the format of their outputs.",
    "engineer": "Technically, the Qwen Deep Research tool leverages Qwen3-Coder for web structure, Qwen-Image for visuals, and Qwen3-TTS for audio, creating a cohesive user experience. It can pull and analyze data from various sources, addressing inconsistencies and generating custom code. This end-to-end approach could set a benchmark for integrated research tools, although comparisons with Google’s NotebookLM suggest varying strengths in content generation versus document management."
  },
  "hype_meter": 4,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-10-22T03:54:49.836Z",
  "updated_at": "2025-10-22T03:54:49.836Z",
  "processing_order": 1761105289836
}