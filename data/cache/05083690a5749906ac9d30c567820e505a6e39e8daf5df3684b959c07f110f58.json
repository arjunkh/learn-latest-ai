{
  "content_hash": "05083690a5749906ac9d30c567820e505a6e39e8daf5df3684b959c07f110f58",
  "share_id": "echvmk",
  "title": "Epistemic Constitutionalism Or: how to avoid coherence bias",
  "optimized_headline": "\"Exploring Epistemic Constitutionalism: A Guide to Overcoming Coherence Bias\"",
  "url": "https://arxiv.org/abs/2601.14295",
  "source": "ArXiv AI",
  "published_at": "2026-01-22T05:00:00.000Z",
  "raw_excerpt": "arXiv:2601.14295v1 Announce Type: new \nAbstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form an",
  "raw_body": "arXiv:2601.14295v1 Announce Type: new \nAbstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "A new paper proposes an 'epistemic constitution' for AI, aiming to regulate how large language models form and express beliefs. It highlights that these models often exhibit source attribution bias, penalizing arguments based on ideological conflicts. By advocating for explicit and contestable norms, the paper suggests a shift towards a more balanced approach in AI reasoning. This matters now as AI increasingly influences decision-making and public discourse.",
  "why_it_matters": [
    "This could immediately impact developers and researchers, guiding them to create more transparent AI systems that better reflect diverse viewpoints.",
    "On a broader scale, this suggests a shift in AI governance, moving towards frameworks that prioritize accountability and inclusivity in AI reasoning processes."
  ],
  "lenses": {
    "eli12": "The idea of an 'epistemic constitution' for AI is like setting rules for a fair debate. Just as rules help ensure everyone gets a chance to speak, these norms could help AI consider multiple viewpoints. This matters for everyday people because it could lead to more reliable and balanced information from AI systems.",
    "pm": "For product managers and founders, this concept highlights the importance of building AI that respects diverse perspectives. By addressing source attribution bias, products could become more trustworthy and user-friendly. This means investing in frameworks that enhance transparency, which could lead to greater user satisfaction and retention.",
    "engineer": "From a technical perspective, the paper critiques current models for enforcing identity-stance coherence, which can distort belief formation. It contrasts two approaches: a Platonic model emphasizing correctness and a Liberal model focusing on procedural norms. This distinction is crucial for engineers as it informs the design of AI systems that balance correctness with a nuanced understanding of diverse sources."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2026-01-23T04:28:23.724Z",
  "updated_at": "2026-01-23T04:28:23.724Z",
  "processing_order": 1769142503725
}