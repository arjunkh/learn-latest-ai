{
  "content_hash": "1b2d246a0bc4884012af8bcb7c9b4c9d60eb6b035d9231727aa7b64671d2b4d1",
  "share_id": "rftby2",
  "title": "Rules fail at the prompt, succeed at the boundary",
  "optimized_headline": "\"How Rules Thrive at Boundaries Despite Failing at Prompts\"",
  "url": "https://www.technologyreview.com/2026/01/28/1131003/rules-fail-at-the-prompt-succeed-at-the-boundary/",
  "source": "MIT Technology Review",
  "published_at": "2026-01-28T14:00:00.000Z",
  "raw_excerpt": "From the Gemini Calendar prompt-injection attack of 2026 to the September 2025 state-sponsored hack using Anthropic’s Claude code as an automated intrusion engine, the coercion of human-in-the-loop agentic actions and fully autonomous agentic workflows are the new attack vector for hackers. In the Anthropic case, roughly 30 organizations across tech, finance, manufacturing, and government were…",
  "raw_body": "From the Gemini Calendar prompt-injection attack of 2026 to the September 2025 state-sponsored hack using Anthropic’s Claude code as an automated intrusion engine, the coercion of human-in-the-loop agentic actions and fully autonomous agentic workflows are the new attack vector for hackers. In the Anthropic case, roughly 30 organizations across tech, finance, manufacturing, and government were…",
  "category": "trends_risks_outlook",
  "category_confidence": "medium",
  "speedrun": "Recent cyberattacks have highlighted a troubling trend where hackers exploit both human involvement and fully automated systems to breach security. Notably, a state-sponsored attack in September 2025 targeted around 30 organizations using Anthropic's Claude code as a tool for intrusion. These incidents show that as AI systems become more integrated, the potential for their misuse increases. Understanding these new attack vectors is crucial for developing effective defenses.",
  "why_it_matters": [
    "Organizations in tech, finance, and government are at immediate risk, as hackers can manipulate both human actions and automated processes to gain access.",
    "This trend signals a broader shift in cyber threats, emphasizing the need for stronger security measures that account for AI's evolving role in operations."
  ],
  "lenses": {
    "eli12": "Hackers are now using advanced methods to trick both people and AI systems into letting them in. Think of it like a thief who knows how to convince the homeowner and pick the lock at the same time. This matters because as AI becomes part of our daily lives, we need to be aware of these risks to stay safe.",
    "pm": "For product managers, this highlights a critical user need for enhanced security features in AI systems. As hackers evolve their tactics, ensuring that both human and automated actions are secure could be essential for maintaining trust. This could lead to increased investment in security tools and protocols.",
    "engineer": "From a technical perspective, the use of Anthropic’s Claude code in these attacks illustrates how AI can be weaponized against organizations. With around 30 entities affected, engineers must consider how to fortify systems against such dual-layered threats. This underscores the importance of building robust defensive mechanisms that account for both human and automated vulnerabilities."
  },
  "hype_meter": 2,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2026-01-29T04:52:55.462Z",
  "updated_at": "2026-01-29T04:52:55.462Z",
  "processing_order": 1769662375464
}