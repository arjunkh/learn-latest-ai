{
  "content_hash": "c623572d7ca780340d3122f4b0a34a67b92aad89ef05565157ab78809db62666",
  "share_id": "eba0yr",
  "title": "EAGLET boosts AI agent performance on longer-horizon tasks by generating custom plans",
  "optimized_headline": "EAGLET Enhances AI Agents' Long-Term Task Performance with Custom Planning",
  "url": "https://venturebeat.com/ai/eaglet-boosts-ai-agent-performance-on-longer-horizon-tasks-by-generating",
  "source": "VentureBeat",
  "published_at": "2025-10-14T22:27:00.000Z",
  "raw_excerpt": "2025 was supposed to be the year of \"AI agents,\" according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as OpenAI, Google, and even Chinese competitors like Alibaba releasing fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. \nBut one big",
  "raw_body": "2025 was supposed to be the year of \"AI agents,\" according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as OpenAI, Google, and even Chinese competitors like Alibaba releasing fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. \nBut one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps. Third-party benchmark tests show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). \nA new academic framework called EAGLET proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. \nDeveloped by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign, EAGLET offers a \"global planner\" that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.\nEAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent's operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.\nAddressing the Planning Problem in Long-Horizon Agents\nMany LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. \nEAGLET tackles this limitation by introducing a global planning module that works alongside the executor agent. \nInstead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.\nA Two-Stage Training Pipeline with No Human Annotations\nEAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. \nThe first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. \nThese plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. \nIn the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.\nIntroducing the Executor Capability Gain Reward (ECGR)\nOne of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). \nThis reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. \nIt also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.\nCompatible with Existing Agents and Models\nThe EAGLET planner is designed to be modular and \"plug-and-play,\" meaning it can be inserted into existing agent pipelines without requiring executor retraining. \nIn evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. \nIt also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.\nState-of-the-Art Performance Across Benchmarks\nEAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.\nAcross all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. \nIn experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. \nOn ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. \nIn ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.\nEven stronger gains were seen with more capable models. \nFor instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. \nIn some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.\nCompared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.\nAdditionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.\nEfficiency Gains in Training and Execution\nCompared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. \nThis efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.\nNo Public Code—Yet\nAs of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. \nVentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.\nEnterprise Deployment Questions Remain\nWhile the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. \nSimilarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.\nEAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.\nReal-Time vs. Pre-Generated Planning\nAnother open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.\nStrategic Tradeoffs for Enterprise Teams\nFor technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.\nPotential Use Cases in Enterprise Settings\nFor enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "EAGLET is a new framework designed to enhance AI agents' performance on complex, long-term tasks by generating detailed plans upfront. Developed by researchers from various universities, it separates planning from execution, which helps reduce errors and improve efficiency. In tests, agents using EAGLET showed significant performance boosts, such as a +19.9 point gain in task completion rates. This advancement could reshape how AI agents operate in real-world applications, especially in sectors like customer support and IT automation.",
  "why_it_matters": [
    "EAGLET could immediately improve AI agents in industries requiring complex task execution, like IT support, enhancing their reliability and efficiency.",
    "This development signals a broader trend towards modular AI systems that can integrate advanced planning capabilities without extensive retraining, potentially transforming agent-based applications."
  ],
  "lenses": {
    "eli12": "EAGLET acts like a GPS for AI agents, helping them navigate complex tasks by creating a detailed plan before they start. This makes the agents less likely to get lost or make mistakes along the way. For everyday users, this means AI can assist more effectively in tasks that require multiple steps, like troubleshooting tech issues or managing projects.",
    "pm": "For product managers, EAGLET presents a way to enhance AI capabilities without extensive retraining, addressing user needs for reliable task completion. Its efficiency could lower costs by reducing the steps needed for task execution, allowing teams to allocate resources more effectively. Implementing EAGLET could lead to faster development cycles and improved user satisfaction.",
    "engineer": "From a technical perspective, EAGLET introduces a modular global planner that operates independently of the executor, improving long-horizon task performance. In benchmarks, it increased task completion rates significantly, with Llama-3.1 models showing a performance rise from 39.5 to 59.4. This approach not only enhances efficiency but also requires less training data, making it an attractive option for developers looking to optimize AI agent workflows."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-10-15T03:52:10.560Z",
  "updated_at": "2025-10-15T03:52:10.560Z",
  "processing_order": 1760500330560
}