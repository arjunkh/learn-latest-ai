{
  "content_hash": "859dcabfa7ef2ca714fb2fb5dad93584271cec3df8ab2b6bbe0439f9c80ac7d9",
  "share_id": "ilgum5",
  "title": "Inside LinkedIn’s generative AI cookbook: How it scaled people search to 1.3 billion users ",
  "optimized_headline": "LinkedIn's AI Cookbook: Scaling User Search to 1.3 Billion Users",
  "url": "https://venturebeat.com/ai/inside-linkedins-generative-ai-cookbook-how-it-scaled-people-search-to-1-3",
  "source": "VentureBeat",
  "published_at": "2025-11-13T16:00:00.000Z",
  "raw_excerpt": "LinkedIn is launching its new AI-powered people search this week, after what seems like a very long wait for what should have been a natural offering for generative AI.\nIt comes a full three years after the launch of ChatGPT and six months after LinkedIn launched its AI job search offering. For technical leaders, this timeline illustrates a key enterprise lesson: Deploying generative AI in real en",
  "raw_body": "LinkedIn is launching its new AI-powered people search this week, after what seems like a very long wait for what should have been a natural offering for generative AI.\nIt comes a full three years after the launch of ChatGPT and six months after LinkedIn launched its AI job search offering. For technical leaders, this timeline illustrates a key enterprise lesson: Deploying generative AI in real enterprise settings is challenging, especially at a scale of 1.3 billion users. It’s a slow, brutal process of pragmatic optimization.\nThe following account is based on several exclusive interviews with the LinkedIn product and engineering team behind the launch.\nFirst, here’s how the product works: A user can now type a natural language query like, \"Who is knowledgeable about curing cancer?\" into LinkedIn’s search bar.\nLinkedIn's old search, based on keywords, would have been stumped. It would have looked only for references to \"cancer\". If a user wanted to get sophisticated, they would have had to run separate, rigid keyword searches for \"cancer\" and then \"oncology\" and manually try to piece the results together.\nThe new AI-powered system, however, understands the intent of the search because the LLM under the hood grasps semantic meaning. It recognizes, for example, that \"cancer\" is conceptually related to \"oncology\" and even less directly, to \"genomics research.\" As a result, it surfaces a far more relevant list of people, including oncology leaders and researchers, even if their profiles don't use the exact word \"cancer.\"\nThe system also balances this relevance with usefulness. Instead of just showing the world's top oncologist (who might be an unreachable third-degree connection), it will also weigh who in your immediate network — like a first-degree connection — is \"pretty relevant\" and can serve as a crucial bridge to that expert.\nSee the video below for an example.\nArguably, though, the more important lesson for enterprise practitioners is the \"cookbook\" LinkedIn has developed: a replicable, multi-stage pipeline of distillation, co-design, and relentless optimization. LinkedIn had to perfect this on one product before attempting it on another.\n\"Don't try to do too much all at once,\" writes Wenjing Zhang, LinkedIn's VP of Engineering, in a  post about the product launch, and who also spoke with VentureBeat last week in an interview. She notes that an earlier \"sprawling ambition\" to build a unified system for all of LinkedIn's products \"stalled progress.\"\nInstead, LinkedIn focused on winning one vertical first. The success of its previously launched AI Job Search — which led to job seekers without a four-year degree being 10% more likely to get hired, according to VP of Product Engineering Erran Berger — provided the blueprint.\nNow, the company is applying that blueprint to a far larger challenge. \"It's one thing to be able to do this across tens of millions of jobs,\" Berger told VentureBeat. \"It's another thing to do this across north of a billion members.\"\nFor enterprise AI builders, LinkedIn's journey provides a technical playbook for what it actually takes to move from a successful pilot to a billion-user-scale product.\nThe new challenge: a 1.3 billion-member graph\nThe job search product created a robust recipe that the new people search product could build upon, Berger explained. \nThe recipe started with with a \"golden data set\" of just a few hundred to a thousand real query-profile pairs, meticulously scored against a detailed 20- to 30-page \"product policy\" document. To scale this for training, LinkedIn used this small golden set to prompt a large foundation model to generate a massive volume of synthetic training data. This synthetic data was used to train a 7-billion-parameter \"Product Policy\" model — a high-fidelity judge of relevance that was too slow for live production but perfect for teaching smaller models.\nHowever, the team hit a wall early on. For six to nine months, they struggled to train a single model that could balance strict policy adherence (relevance) against user engagement signals. The \"aha moment\" came when they realized they needed to break the problem down. They distilled the 7B policy model into a 1.7B teacher model focused solely on relevance. They then paired it with separate teacher models trained to predict specific member actions, such as job applications for the jobs product, or connecting and following for people search. This \"multi-teacher\" ensemble produced soft probability scores that the final student model learned to mimic via KL divergence loss.\nThe resulting architecture operates as a two-stage pipeline. First, a larger 8B parameter model handles broad retrieval, casting a wide net to pull candidates from the graph. Then, the highly distilled student model takes over for fine-grained ranking. While the job search product successfully deployed a 0.6B (600-million) parameter student, the new people search product required even more aggressive compression. As Zhang notes, the team pruned their new student model from 440M down to just 220M parameters, achieving the necessary speed for 1.3 billion users with less than 1% relevance loss.\nBut applying this to people search broke the old architecture. The new problem included not just ranking but also retrieval.\n“A billion records,\" Berger said, is a \"different beast.\"\nThe team’s prior retrieval stack was built on CPUs. To handle the new scale and the latency demands of a \"snappy\" search experience, the team had to move its indexing to GPU-based infrastructure. This was a foundational architectural shift that the job search product did not require.\nOrganizationally, LinkedIn benefited from multiple approaches. For a time, LinkedIn had two separate teams — job search and people search — attempting to solve the problem in parallel. But once the job search team achieved its breakthrough using the policy-driven distillation method, Berger and his leadership team intervened. They brought over the architects of the job search win —  product lead Rohan Rajiv and engineering lead Wenjing Zhang — to transplant their 'cookbook' directly to the new domain.\nDistilling for a 10x throughput gain\nWith the retrieval problem solved, the team faced the ranking and efficiency challenge. This is where the cookbook was adapted with new, aggressive optimization techniques.\nZhang’s technical post (I’ll insert the link once it goes live) provides the specific details our audience of AI engineers will appreciate. One of the more significant optimizations was input size.\nTo feed the model, the team trained another LLM with reinforcement learning (RL) for a single purpose: to summarize the input context. This \"summarizer\" model was able to reduce the model's input size by 20-fold with minimal information loss.\nThe combined result of the 220M-parameter model and the 20x input reduction? A 10x increase in ranking throughput, allowing the team to serve the model efficiently to its massive user base.\nPragmatism over hype: building tools, not agents\nThroughout our discussions, Berger was adamant about something else that might catch peoples’ attention: The real value for enterprises today lies in perfecting recommender systems, not in chasing \"agentic hype.\" He also refused to talk about the specific models that the company used for the searches, suggesting it almost doesn't matter. The company selects models based on which one it finds the most efficient for the task.\nThe new AI-powered people search is a manifestation of Berger’s philosophy that it’s best to optimize the recommender system first. The architecture includes a new \"intelligent query routing layer,\" as Berger explained, that itself is LLM-powered. This router pragmatically decides if a user's query — like \"trust expert\" — should go to the new semantic, natural-language stack or to the old, reliable lexical search.\nThis entire, complex system is designed to be a \"tool\" that a future agent will use, not the agent itself.\n\"Agentic products are only as good as the tools that they use to accomplish tasks for people,\" Berger said. \"You can have the world's best reasoning model, and if you're trying to use an agent to do people search but the people search engine is not very good, you're not going to be able to deliver.\" \nNow that the people search is available, Berger suggested that one day the company will be offering agents to use it. But he didn’t provide details on timing. He also said the recipe used for job and people search will be spread across the company’s other products.\nFor enterprises building their own AI roadmaps, LinkedIn's playbook is clear:\n\nBe pragmatic: Don't try to boil the ocean. Win one vertical, even if it takes 18 months.\n\nCodify the \"cookbook\": Turn that win into a repeatable process (policy docs, distillation pipelines, co-design).\n\nOptimize relentlessly: The real 10x gains come after the initial model, in pruning, distillation, and creative optimizations like an RL-trained summarizer.\n\nLinkedIn's journey shows that for real-world enterprise AI, emphasis on specific models or cool agentic systems should take a back seat. The durable, strategic advantage comes from mastering the pipeline — the 'AI-native' cookbook of co-design, distillation, and ruthless optimization.\n(Editor's note: We will be publishing a full-length podcast with LinkedIn's Erran Berger, which will dive deeper into these technical details, on the VentureBeat podcast feed soon.)",
  "category": "in_action_real_world",
  "category_confidence": "medium",
  "speedrun": "LinkedIn has launched its new AI-powered people search, a significant upgrade that allows users to ask natural language questions, like finding experts in oncology. This new system leverages a large language model to understand intent and deliver relevant results, even if the exact terms aren’t used in profiles. The rollout comes three years after ChatGPT's debut and highlights the complexities of deploying generative AI at scale for 1.3 billion users. This matters now as it sets a precedent for other enterprises looking to implement similar technologies.",
  "why_it_matters": [
    "Job seekers without a four-year degree saw a 10% increase in hiring likelihood with LinkedIn's previous AI job search, illustrating immediate benefits for users.",
    "LinkedIn's approach signals a broader industry shift towards optimizing AI tools for specific tasks rather than pursuing generalized AI solutions."
  ],
  "lenses": {
    "eli12": "LinkedIn's new AI-powered people search lets you ask questions in everyday language, making it easier to find the right people. Instead of searching for keywords, it understands the meaning behind your queries. Imagine asking a friend for recommendations instead of just looking up names. This matters because it could help you connect with experts more efficiently in your professional network.",
    "pm": "For product managers and founders, LinkedIn's experience shows the importance of focusing on one area before expanding. The success of their AI job search informed the new people search, highlighting user needs and efficiency gains. This means that refining a product in stages could lead to better outcomes and a clearer path to scaling.",
    "engineer": "From a technical perspective, LinkedIn's new people search utilizes a two-stage model architecture with an 8-billion parameter model for broad retrieval and a compressed 220-million parameter model for ranking. They achieved a 10x increase in throughput by optimizing input sizes through a reinforcement learning-trained summarizer. This approach emphasizes the importance of distillation and efficient model architecture in handling large-scale AI applications."
  },
  "hype_meter": 4,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-11-14T03:59:32.747Z",
  "updated_at": "2025-11-14T03:59:32.747Z",
  "processing_order": 1763092772749
}