{
  "content_hash": "1080b13aa838902501c5471a1c6649c592646281f4f3f7833a31561f641481e0",
  "share_id": "oefjl1",
  "title": "OpenAGI emerges from stealth with an AI agent that it claims crushes OpenAI and Anthropic",
  "optimized_headline": "OpenAGI Launches Stealthy AI Agent, Claims Superiority Over OpenAI and Anthropic",
  "url": "https://venturebeat.com/ai/openagi-emerges-from-stealth-with-an-ai-agent-that-it-claims-crushes-openai",
  "source": "VentureBeat",
  "published_at": "2025-12-01T14:00:00.000Z",
  "raw_excerpt": "A stealth artificial intelligence startup founded by an MIT researcher emerged this morning with an ambitious claim: its new AI model can control computers better than systems built by OpenAI and Anthropic — at a fraction of the cost.\nOpenAGI, led by chief executive Zengyi Qin, released Lux, a foundation model designed to operate computers autonomously by interpreting screenshots and executing act",
  "raw_body": "A stealth artificial intelligence startup founded by an MIT researcher emerged this morning with an ambitious claim: its new AI model can control computers better than systems built by OpenAI and Anthropic — at a fraction of the cost.\nOpenAGI, led by chief executive Zengyi Qin, released Lux, a foundation model designed to operate computers autonomously by interpreting screenshots and executing actions across desktop applications. The San Francisco-based company says Lux achieves an 83.6 percent success rate on Online-Mind2Web, a benchmark that has become the industry's most rigorous test for evaluating AI agents that control computers.\nThat score is a significant leap over the leading models from well-funded competitors. OpenAI's Operator, released in January, scores 61.3 percent on the same benchmark. Anthropic's Claude Computer Use achieves 56.3 percent.\n\"Traditional LLM training feeds a large amount of text corpus into the model. The model learns to produce text,\" Qin said in an exclusive interview with VentureBeat. \"By contrast, our model learns to produce actions. The model is trained with a large amount of computer screenshots and action sequences, allowing it to produce actions to control the computer.\"\nThe announcement arrives at a pivotal moment for the AI industry. Technology giants and startups alike have poured billions of dollars into developing autonomous agents capable of navigating software, booking travel, filling out forms, and executing complex workflows. OpenAI, Anthropic, Google, and Microsoft have all released or announced agent products in the past year, betting that computer-controlling AI will become as transformative as chatbots.\nYet independent research has cast doubt on whether current agents are as capable as their creators suggest.\nWhy university researchers built a tougher benchmark to test AI agents—and what they discovered\nThe Online-Mind2Web benchmark, developed by researchers at Ohio State University and the University of California, Berkeley, was designed specifically to expose the gap between marketing claims and actual performance.\nPublished in April and accepted to the Conference on Language Modeling 2025, the benchmark comprises 300 diverse tasks across 136 real websites — everything from booking flights to navigating complex e-commerce checkouts. Unlike earlier benchmarks that cached parts of websites, Online-Mind2Web tests agents in live online environments where pages change dynamically and unexpected obstacles appear.\nThe results, according to the researchers, painted \"a very different picture of the competency of current agents, suggesting over-optimism in previously reported results.\"\nWhen the Ohio State team tested five leading web agents with careful human evaluation, they found that many recent systems — despite heavy investment and marketing fanfare — did not outperform SeeAct, a relatively simple agent released in January 2024. Even OpenAI's Operator, the best performer among commercial offerings in their study, achieved only 61 percent success.\n\"It seemed that highly capable and practical agents were maybe indeed just months away,\" the researchers wrote in a blog post accompanying their paper. \"However, we are also well aware that there are still many fundamental gaps in research to fully autonomous agents, and current agents are probably not as competent as the reported benchmark numbers may depict.\"\nThe benchmark has gained traction as an industry standard, with a public leaderboard hosted on Hugging Face tracking submissions from research groups and companies.\nHow OpenAGI trained its AI to take actions instead of just generating text\nOpenAGI's claimed performance advantage stems from what the company calls \"Agentic Active Pre-training,\" a training methodology that differs fundamentally from how most large language models learn.\nConventional language models train on vast text corpora, learning to predict the next word in a sequence. The resulting systems excel at generating coherent text but were not designed to take actions in graphical environments.\nLux, according to Qin, takes a different approach. The model trains on computer screenshots paired with action sequences, learning to interpret visual interfaces and determine which clicks, keystrokes, and navigation steps will accomplish a given goal.\n\"The action allows the model to actively explore the computer environment, and such exploration generates new knowledge, which is then fed back to the model for training,\" Qin told VentureBeat. \"This is a naturally self-evolving process, where a better model produces better exploration, better exploration produces better knowledge, and better knowledge leads to a better model.\"\nThis self-reinforcing training loop, if it functions as described, could help explain how a smaller team might achieve results that elude larger organizations. Rather than requiring ever-larger static datasets, the approach would allow the model to continuously improve by generating its own training data through exploration.\nOpenAGI also claims significant cost advantages. The company says Lux operates at roughly one-tenth the cost of frontier models from OpenAI and Anthropic while executing tasks faster.\nUnlike browser-only competitors, Lux can control Slack, Excel, and other desktop applications\nA critical distinction in OpenAGI's announcement: Lux can control applications across an entire desktop operating system, not just web browsers.\nMost commercially available computer-use agents, including early versions of Anthropic's Claude Computer Use, focus primarily on browser-based tasks. That limitation excludes vast categories of productivity work that occur in desktop applications — spreadsheets in Microsoft Excel, communications in Slack, design work in Adobe products, code editing in development environments.\nOpenAGI says Lux can navigate these native applications, a capability that would substantially expand the addressable market for computer-use agents. The company is releasing a developer software development kit alongside the model, allowing third parties to build applications on top of Lux.\nThe company is also working with Intel to optimize Lux for edge devices, which would allow the model to run locally on laptops and workstations rather than requiring cloud infrastructure. That partnership could address enterprise concerns about sending sensitive screen data to external servers.\n\"We are partnering with Intel to optimize our model on edge devices, which will make it the best on-device computer-use model,\" Qin said.\nThe company confirmed it is in exploratory discussions with AMD and Microsoft about additional partnerships.\nWhat happens when you ask an AI agent to copy your bank details\nComputer-use agents present novel safety challenges that do not arise with conventional chatbots. An AI system capable of clicking buttons, entering text, and navigating applications could, if misdirected, cause significant harm — transferring money, deleting files, or exfiltrating sensitive information.\nOpenAGI says it has built safety mechanisms directly into Lux. When the model encounters requests that violate its safety policies, it refuses to proceed and alerts the user.\nIn an example provided by the company, when a user asked the model to \"copy my bank details and paste it into a new Google doc,\" Lux responded with an internal reasoning step: \"The user asks me to copy the bank details, which are sensitive information. Based on the safety policy, I am not able to perform this action.\" The model then issued a warning to the user rather than executing the potentially dangerous request.\nSuch safeguards will face intense scrutiny as computer-use agents proliferate. Security researchers have already demonstrated prompt injection attacks against early agent systems, where malicious instructions embedded in websites or documents can hijack an agent's behavior. Whether Lux's safety mechanisms can withstand adversarial attacks remains to be tested by independent researchers.\nThe MIT researcher who built two of GitHub's most downloaded AI models\nQin brings an unusual combination of academic credentials and entrepreneurial experience to OpenAGI.\nHe completed his doctorate at the Massachusetts Institute of Technology in 2025, where his research focused on computer vision, robotics, and machine learning. His academic work appeared in top venues including the Conference on Computer Vision and Pattern Recognition, the International Conference on Learning Representations, and the International Conference on Machine Learning.\nBefore founding OpenAGI, Qin built several widely adopted AI systems. JetMoE, a large language model he led development on, demonstrated that a high-performing model could be trained from scratch for less than $100,000 — a fraction of the tens of millions typically required. The model outperformed Meta's LLaMA2-7B on standard benchmarks, according to a technical report that attracted attention from MIT's Computer Science and Artificial Intelligence Laboratory.\nHis previous open-source projects achieved remarkable adoption. OpenVoice, a voice cloning model, accumulated approximately 35,000 stars on GitHub and ranked in the top 0.03 percent of open-source projects by popularity. MeloTTS, a text-to-speech system, has been downloaded more than 19 million times, making it one of the most widely used audio AI models since its 2024 release.\nQin also co-founded MyShell, an AI agent platform that has attracted six million users who have collectively built more than 200,000 AI agents. Users have had more than one billion interactions with agents on the platform, according to the company.\nInside the billion-dollar race to build AI that controls your computer\nThe computer-use agent market has attracted intense interest from investors and technology giants over the past year.\nOpenAI released Operator in January, allowing users to instruct an AI to complete tasks across the web. Anthropic has continued developing Claude Computer Use, positioning it as a core capability of its Claude model family. Google has incorporated agent features into its Gemini products. Microsoft has integrated agent capabilities across its Copilot offerings and Windows.\nYet the market remains nascent. Enterprise adoption has been limited by concerns about reliability, security, and the ability to handle edge cases that occur frequently in real-world workflows. The performance gaps revealed by benchmarks like Online-Mind2Web suggest that current systems may not be ready for mission-critical applications.\nOpenAGI enters this competitive landscape as an independent alternative, positioning superior benchmark performance and lower costs against the massive resources of its well-funded rivals. The company's Lux model and developer SDK are available beginning today.\nWhether OpenAGI can translate benchmark dominance into real-world reliability remains the central question. The AI industry has a long history of impressive demos that falter in production, of laboratory results that crumble against the chaos of actual use. Benchmarks measure what they measure, and the distance between a controlled test and an 8-hour workday full of edge cases, exceptions, and surprises can be vast.\nBut if Lux performs in the wild the way it performs in the lab, the implications extend far beyond one startup's success. It would suggest that the path to capable AI agents runs not through the largest checkbooks but through the cleverest architectures—that a small team with the right ideas can outmaneuver the giants.\nThe technology industry has seen that story before. It rarely stays true for long.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "OpenAGI, a stealth startup led by MIT researcher Zengyi Qin, has launched Lux, an AI model that claims to outperform OpenAI and Anthropic in controlling computers. Lux boasts an 83.6% success rate on the Online-Mind2Web benchmark, significantly higher than OpenAI's 61.3% and Anthropic's 56.3%. This breakthrough comes at a crucial time as the AI industry races to develop autonomous agents, and OpenAGI's approach could reshape expectations around performance and cost.",
  "why_it_matters": [
    "OpenAGI's Lux could provide businesses with a more efficient and cost-effective AI solution for automating tasks, enhancing productivity for users.",
    "This launch signals a potential shift in the AI market, where smaller, innovative companies could challenge established giants, changing the competitive landscape."
  ],
  "lenses": {
    "eli12": "OpenAGI has introduced Lux, an AI that can control computers better than competitors at a lower cost. Think of it like a new car that drives itself more smoothly than the old models, but at a fraction of the price. This matters because it could make advanced AI technology more accessible to everyday users, improving how we interact with our devices.",
    "pm": "For product managers and founders, Lux represents a new user need for more capable and affordable AI agents. The model's ability to operate across various desktop applications could reduce costs and improve efficiency in workflows. This means businesses could invest in AI without the hefty price tag typically associated with advanced models.",
    "engineer": "From a technical perspective, Lux's success stems from its unique training method, 'Agentic Active Pre-training,' which focuses on learning actions through screenshots rather than just text. With an 83.6% success rate on the Online-Mind2Web benchmark, Lux outperforms major competitors significantly. However, its real-world performance still needs to be validated against the complexities of everyday tasks."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-12-02T04:05:59.232Z",
  "updated_at": "2025-12-02T04:05:59.232Z",
  "processing_order": 1764648359235
}