{
  "content_hash": "ff0b6cb983fb2c6924b34debc7ae6d6fa03ea0c9919ebd302d7c4b03d7e32860",
  "share_id": "qtbiks",
  "title": "Qwen3-Max Thinking beats Gemini 3 Pro and GPT-5.2 on Humanity's Last Exam (with search)",
  "optimized_headline": "Qwen3-Max Outperforms Gemini 3 Pro and GPT-5.2 in Humanity's Final Exam",
  "url": "https://venturebeat.com/technology/qwen3-max-thinking-beats-gemini-3-pro-and-gpt-5-2-on-humanitys-last-exam",
  "source": "VentureBeat",
  "published_at": "2026-01-26T23:42:00.000Z",
  "raw_excerpt": "Chinese AI and tech firms continue to impress with their development of cutting-edge, state-of-the-art AI language models.\nToday, the one drawing eyeballs is Alibaba Cloud's Qwen Team of AI researchers and its unveiling of a new proprietary language reasoning model, Qwen3-Max-Thinking.\nYou may recall, as VentureBeat covered last year, that Qwen has made a name for itself in the fast-moving global ",
  "raw_body": "Chinese AI and tech firms continue to impress with their development of cutting-edge, state-of-the-art AI language models.\nToday, the one drawing eyeballs is Alibaba Cloud's Qwen Team of AI researchers and its unveiling of a new proprietary language reasoning model, Qwen3-Max-Thinking.\nYou may recall, as VentureBeat covered last year, that Qwen has made a name for itself in the fast-moving global AI marketplace by shipping a variety of powerful, open source models in various modalities, from text to image to spoken audio. The company even earned an endorsement from U.S. tech lodgings giant Airbnb, whose CEO and co-founder Brian Chesky said the company was relying on Qwen's free, open source models as a more affordable alternative to U.S. offerings like those of OpenAI.\nNow, with the proprietary Qwen3-Max-Thinking, the Qwen Team is aiming to match and, in some cases, outpace the reasoning capabilities of GPT-5.2 and Gemini 3 Pro through architectural efficiency and agentic autonomy.\nThe release comes at a critical juncture. Western labs have largely defined the \"reasoning\" category (often dubbed \"System 2\" logic), but Qwen’s latest benchmarks suggest the gap has closed. \nIn addition, the company's relatively affordable API pricing strategy aggressively targets enterprise adoption. However, as it is a Chinese model, some U.S. firms with strict national security requirements and considerations may be wary of adopting it.\nThe Architecture: \"Test-Time Scaling\" Redefined\nThe core innovation driving Qwen3-Max-Thinking is a departure from standard inference methods. While most models generate tokens linearly, Qwen3 utilizes a \"heavy mode\" driven by a technique known as \"Test-time scaling.\"\nIn simple terms, this technique allows the model to trade compute for intelligence. But unlike naive \"best-of-N\" sampling—where a model might generate 100 answers and pick the best one — Qwen3-Max-Thinking employs an experience-cumulative, multi-round strategy.\nThis approach mimics human problem-solving. When the model encounters a complex query, it doesn't just guess; it engages in iterative self-reflection. It uses a proprietary \"take-experience\" mechanism to distill insights from previous reasoning steps. This allows the model to:\n\nIdentify Dead Ends: Recognize when a line of reasoning is failing without needing to fully traverse it.\n\nFocus Compute: Redirect processing power toward \"unresolved uncertainties\" rather than re-deriving known conclusions.\n\nThe efficiency gains are tangible. By avoiding redundant reasoning, the model integrates richer historical context into the same window. The Qwen team reports that this method drove massive performance jumps without exploding token costs:\n\nGPQA (PhD-level science): Scores improved from 90.3 to 92.8.\n\nLiveCodeBench v6: Performance jumped from 88.0 to 91.4.\n\nBeyond Pure Thought: Adaptive Tooling\nWhile \"thinking\" models are powerful, they have historically been siloed — great at math, but poor at browsing the web or running code. Qwen3-Max-Thinking bridges this gap by effectively integrating \"thinking and non-thinking modes\".\nThe model features adaptive tool-use capabilities, meaning it autonomously selects the right tool for the job without manual user prompting. It can seamlessly toggle between:\n\nWeb Search & Extraction: For real-time factual queries.\n\nMemory: To store and recall user-specific context.\n\nCode Interpreter: To write and execute Python snippets for computational tasks.\n\nIn \"Thinking Mode,\" the model supports these tools simultaneously. This capability is critical for enterprise applications where a model might need to verify a fact (Search), calculate a projection (Code Interpreter), and then reason about the strategic implication (Thinking) all in one turn.\nEmpirically, the team notes that this combination \"effectively mitigates hallucinations,\" as the model can ground its reasoning in verifiable external data rather than relying solely on its training weights.\nBenchmark Analysis: The Data Story\nQwen is not shy about direct comparisons. \nOn HMMT Feb 25, a rigorous reasoning benchmark, Qwen3-Max-Thinking scored 98.0, edging out Gemini 3 Pro (97.5) and significantly leading DeepSeek V3.2 (92.5).\nHowever, the most significant signal for developers is arguably Agentic Search. On \"Humanity's Last Exam\" (HLE) — the benchmark that measures performance on 3,000 \"Google-proof\" graduate-level questions across math, science, computer science, humanities and engineering — Qwen3-Max-Thinking, equipped with web search tools, scored 49.8, beating both Gemini 3 Pro (45.8) and GPT-5.2-Thinking (45.5) . \nThis suggests that Qwen3-Max-Thinking’s architecture is uniquely suited for complex, multi-step agentic workflows where external data retrieval is necessary. \nIn coding tasks, the model also shines. On Arena-Hard v2, it posted a score of 90.2, leaving competitors like Claude-Opus-4.5 (76.7) far behind.\nThe Economics of Reasoning: Pricing Breakdown\nFor the first time, we have a clear look at the economics of Qwen's top-tier reasoning model. Alibaba Cloud has positioned qwen3-max-2026-01-23 as a premium but accessible offering on its API.\n\nInput: $1.20 per 1 million tokens (for standard contexts <= 32k).\n\nOutput: $6.00 per 1 million tokens.\n\nOn a base level, here's how Qwen3-Max-Thinking stacks up:\n\n\nModel\n\nInput (/1M)\n\nOutput (/1M)\n\nTotal Cost\n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nQwen 3 Plus\n\n$0.40\n\n$1.20\n\n$1.60\n\nAlibaba Cloud\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nGemini 3 Flash Preview\n\n$0.50\n\n$3.00\n\n$3.50\n\nGoogle\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen3-Max Thinking (2026-01-23)\n\n$1.20\n\n$6.00\n\n$7.20\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Opus 4.5\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nThis pricing structure is aggressive, undercutting many legacy flagship models while offering state-of-the-art performance. \nHowever, developers should note the granular pricing for the new agentic capabilities, as Qwen separates the cost of \"thinking\" (tokens) from the cost of \"doing\" (tool use).\n\nAgent Search Strategy: Both standard search_strategy:agent and the more advanced search_strategy:agent_max are priced at $10 per 1,000 calls.\n\nNote: The agent_max strategy is currently marked as a \"Limited Time Offer,\" suggesting its price may rise later.\n\n\nWeb Search: Priced at $10 per 1,000 calls via the Responses API.\n\nPromotional Free Tier:To encourage adoption of its most advanced features, Alibaba Cloud is currently offering two key tools for free for a limited time:\n\nWeb Extractor: Free (Limited Time).\n\nCode Interpreter: Free (Limited Time).\n\nThis pricing model (low token cost + à la carte tool pricing) allows developers to build complex agents that are cost-effective for text processing, while paying a premium only when external actions—like a live web search—are explicitly triggered.\nDeveloper Ecosystem\nRecognizing that performance is useless without integration, Alibaba Cloud has ensured Qwen3-Max-Thinking is drop-in ready.\n\nOpenAI Compatibility: The API supports the standard OpenAI format, allowing teams to switch models by simply changing the base_url and model name.\n\nAnthropic Compatibility: In a savvy move to capture the coding market, the API also supports the Anthropic protocol. This makes Qwen3-Max-Thinking compatible with Claude Code, a popular agentic coding environment.\n\nThe Verdict\nQwen3-Max-Thinking represents a maturation of the AI market in 2026. It moves the conversation beyond \"who has the smartest chatbot\" to \"who has the most capable agent.\" \nBy combining high-efficiency reasoning with adaptive, autonomous tool use—and pricing it to move—Qwen has firmly established itself as a top-tier contender for the enterprise AI throne.\nFor developers and enterprises, the \"Limited Time Free\" windows on Code Interpreter and Web Extractor suggest now is the time to experiment. The reasoning wars are far from over, but Qwen has just deployed a very heavy hitter.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Alibaba Cloud's Qwen Team has launched Qwen3-Max-Thinking, a new AI language model that outperforms competitors like GPT-5.2 and Gemini 3 Pro in reasoning tasks. It scored 49.8 on 'Humanity's Last Exam,' surpassing Gemini 3 Pro's 45.8 and GPT-5.2's 45.5. This model utilizes a unique 'Test-time scaling' approach, enhancing its reasoning capabilities while offering competitive pricing. The release is timely as it challenges the dominance of Western AI models in the reasoning category.",
  "why_it_matters": [
    "Qwen3-Max-Thinking could provide enterprises with a more affordable and effective AI solution for complex reasoning tasks.",
    "The model's performance suggests a significant shift in the AI landscape, indicating that Chinese firms can compete with established Western technologies."
  ],
  "lenses": {
    "eli12": "Qwen3-Max-Thinking is like a student who learns from their mistakes instead of just guessing answers. It engages in self-reflection, leading to better problem-solving. This matters because it could help everyday people access smarter AI tools that understand context and provide accurate information.",
    "pm": "For product managers, Qwen3-Max-Thinking addresses the user need for advanced reasoning and tool integration. Its competitive pricing could lead to lower costs for enterprises, allowing for more efficient AI use in various applications. This might encourage teams to adopt AI solutions that enhance productivity without breaking the budget.",
    "engineer": "Technically, Qwen3-Max-Thinking employs a 'Test-time scaling' method that allows it to optimize compute resources for better reasoning. With scores of 98.0 on the HMMT benchmark and 49.8 on 'Humanity's Last Exam,' it outperforms key competitors. This model's architecture enables it to handle complex workflows efficiently, integrating web search and code execution seamlessly."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2026-01-27T04:32:56.719Z",
  "updated_at": "2026-01-27T04:32:56.719Z",
  "processing_order": 1769488376720
}