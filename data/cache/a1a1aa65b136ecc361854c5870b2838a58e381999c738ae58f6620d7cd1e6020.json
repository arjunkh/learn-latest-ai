{
  "content_hash": "a1a1aa65b136ecc361854c5870b2838a58e381999c738ae58f6620d7cd1e6020",
  "share_id": "ega5ir",
  "title": "Even Google and Replit struggle to deploy AI agents reliably — here's why",
  "optimized_headline": "Google and Replit's AI agent deployment challenges: What’s behind the struggle?",
  "url": "https://venturebeat.com/orchestration/even-google-and-replit-struggle-to-deploy-ai-agents-reliably-heres-why",
  "source": "VentureBeat",
  "published_at": "2025-12-19T19:00:00.000Z",
  "raw_excerpt": "2025 was supposed to be the year of the AI agent, right? \nNot quite, acknowledge Google Cloud and Replit — two big players in the AI agent space and partners in the \"vibe coding\" movement — at a recent VB Impact Series event.\nEven as they build out agentic tools themselves, leaders from the two companies say the capabilities aren’t quite there yet. \nThis constrained reality comes down to struggles",
  "raw_body": "2025 was supposed to be the year of the AI agent, right? \nNot quite, acknowledge Google Cloud and Replit — two big players in the AI agent space and partners in the \"vibe coding\" movement — at a recent VB Impact Series event.\nEven as they build out agentic tools themselves, leaders from the two companies say the capabilities aren’t quite there yet. \nThis constrained reality comes down to struggles with legacy workflows, fragmented data, and immature governance models. Also, enterprises fundamentally misunderstand that agents aren’t like other technologies: They require a fundamental rethink and reworking of workflows and processes. \nWhen enterprises are building agents to automate work, “most of them are toy examples,” Amjad Masad, CEO and founder of Replit, said during the event. “They get excited, but when they start rolling it out, it's not really working very well.”\nBuilding agents based on Replit’s own mistakes\nReliability and integration, rather than intelligence itself, are two primary barriers to AI agent success, Masad noted. Agents frequently fail when run for extended periods, accumulate errors, or lack access to clean, well-structured data. \nThe problem with enterprise data is it’s messy — it’s structured, unstructured, and stored all over the place — and crawling it is a challenge. Added to that, there are many unwritten things that people do that are difficult to encode in agents, Masad said. \n“The idea that companies are just going to turn on agents and agents will replace workers or do workflow automations automatically, it's just not the case today,” he said. “The tooling is not there.” \nGoing beyond agents are computer use tools, which can take over a user’s workspace for basic tasks like web browsing. But these are still in their infancy and can be buggy, unreliable, and even dangerous, despite the accelerated hype. \n“The problem is computer use models are really bad right now,” Masad said. “They're expensive, they're slow, they're making progress, but they're only about a year old.” \nReplit is learning from its own blunder earlier this year, when its AI coder wiped a company's entire code base in a test run. Masad conceded: “The tools were not mature enough,” noting that the company has since isolated development from production. \nTechniques such as testing-in-the-loop, verifiable execution, and development isolation are essential, he noted, even as they can be highly resource-intensive. Replit incorporated in-the-loop capabilities into version 3 of its agent, and Masad said that its next-gen agent can work autonomously for 200 minutes; some have run it for 20 hours. \nStill, he acknowledged that users have expressed frustration around lag times. When they put in a “hefty prompt,” they may have to wait 20 minutes or longer. Ideally, they’ve expressed that they want to be involved in more of a creative loop where they can enter numerous prompts, work on multiple tasks at once, and adjust the design as the agent is working. \n“The way to solve that is parallelism, to create multiple agent loops and have them work on these independent features while allowing you to do the creative work at the same time,” he said. \nAgents require a cultural shift\nBeyond the technical perspective, there’s a cultural hurdle: Agents operate probabilistically, but traditional enterprises are structured around deterministic processes, noted Mike Clark, director of product development at Google Cloud. This creates a cultural and operational mismatch as LLMs steam in with all-new tools, orchestration frameworks and processes. \n“We don't know how to think about agents,” Clark said. “We don't know how to solve for what agents can do.”\nThe companies doing it right are being driven by bottoms-up processes, he noted: no-code and low-code software and tool creation in the trenches funneling up to larger agents. As of yet, the deployments that are successful are narrow, carefully scoped and heavily supervised. \n“If I look at 2025 and this promise of it being the year of agents, it was the year a lot of folks spent building prototypes,” Clark said. “Now we’re in the middle of this huge scale phase.”\nHow do you secure a pasture-less world?\nAnother struggle is AI agent security, which also requires a rethink of traditional processes, Clark noted.  \nSecurity perimeters have been drawn around everything — but that doesn’t work when agents need to be able to access many different resources to make the best decisions, said Clark. \n“It's really changing our security models, changing our base level,” he said. “What does least privilege mean in a pasture-less defenseless world?”\nUltimately, there must be a governance rethink on the part of the whole industry, and enterprises must align on a threat model around agents. \nClark pointed out the disparity: “If you look at some of your governance processes, you'll be very surprised that the origin of those processes was somebody on an IBM electric typewriter typing in triplicate and handing that to three people. That is not the world we live in today.”",
  "category": "in_action_real_world",
  "category_confidence": "medium",
  "speedrun": "Unable to summarize article at this time.",
  "why_it_matters": [
    "Summary unavailable",
    "Please check original source"
  ],
  "lenses": {
    "eli12": "We couldn't process this article right now.",
    "pm": "Article processing failed - check the original source for details.",
    "engineer": "JSON parsing error - the AI response was malformed."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-12-20T04:00:23.145Z",
  "updated_at": "2025-12-20T04:00:23.145Z",
  "processing_order": 1766203223146
}