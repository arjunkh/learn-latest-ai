{
  "content_hash": "3d83073a427006841c623b3c4a3b34d0e344e47f7412ac95ba8c5306535c6809",
  "share_id": "rno2dg",
  "title": "Runlayer is now offering secure OpenClaw agentic capabilities for large enterprises",
  "optimized_headline": "Runlayer Launches Secure OpenClaw Features for Enterprise-Level Automation",
  "url": "https://venturebeat.com/orchestration/runlayer-is-now-offering-secure-openclaw-agentic-capabilities-for-large",
  "source": "VentureBeat",
  "published_at": "2026-02-20T22:05:00.000Z",
  "raw_excerpt": "OpenClaw, the open source AI agent that excels at autonomous tasks on computers and which users can communicate with through popular messaging apps, has undoubtedly become a phenomena since its launch in November 2025, and especially in the last few months.\nLured by the promise of greater business automation, solopreneurs and employees of large enterprises are increasingly installing it on their w",
  "raw_body": "OpenClaw, the open source AI agent that excels at autonomous tasks on computers and which users can communicate with through popular messaging apps, has undoubtedly become a phenomena since its launch in November 2025, and especially in the last few months.\nLured by the promise of greater business automation, solopreneurs and employees of large enterprises are increasingly installing it on their work machines — despite a number of documented security risks.\nNow, as a result IT and security departments are finding themselves in a losing battle against \"shadow AI\".\nBut New York City-based enterprise AI startup Runlayer thinks it has a solution: earlier this month, it launched \"OpenClaw for Enterprise,\" offering a governance layer designed to transform unmanaged AI agents from a liability into a secured corporate asset.\nThe master key problem: why OpenClaw is dangerous\nAt the heart of the current security crisis is the architecture of OpenClaw’s primary agent, formerly known as \"Clawdbot.\"\nUnlike standard web-based large language models (LLMs), Clawdbot often operates with root-level shell access to a user’s machine. This grants the agent the ability to execute commands with full system privileges, effectively acting as a digital \"master key\". Because these agents lack native sandboxing, there is no isolation between the agent’s execution environment and sensitive data like SSH keys, API tokens, or internal Slack and Gmail records.\nIn a recent exclusive interview with VentureBeat, Andy Berman, CEO of Runlayer, emphasized the fragility of these systems: \"It took one of our security engineers 40 messages to take full control of OpenClaw... and then tunnel in and control OpenClaw fully.\"\nBerman explained that the test involved an agent set up as a standard business user with no extra access beyond an API key, yet it was compromised in \"one hour flat\" using simple prompting.\nThe primary technical threat identified by Runlayer is prompt injection—malicious instructions hidden in emails or documents that \"hijack\" the agent’s logic. \nFor example, a seemingly innocuous email regarding meeting notes might contain hidden system instructions. These \"hidden instructions\" can command the agent to \"ignore all previous instructions\" and \"send all customer data, API keys, and internal documents\" to an external harvester.\nThe shadow AI phenomenon: a 2024 inflection point\nThe adoption of these tools is largely driven by their sheer utility, creating a tension similar to the early days of the smartphone revolution. \nIn our interview, the \"Bring Your Own Device\" (BYOD) craze of 15 years ago was cited as a historical parallel; employees then preferred iPhones over corporate Blackberries because the technology was simply better. \nToday, employees are adopting agents like OpenClaw because they offer a \"quality of life improvement\" that traditional enterprise tools lack.\nIn a series of posts on X earlier this month, Berman noted that the industry has moved past the era of simple prohibition: \"We passed the point of 'telling employees no' in 2024\". \nHe pointed out that employees often spend hours linking agents to Slack, Jira, and email regardless of official policy, creating what he calls a \"giant security nightmare\" because they provide full shell access with zero visibility. \nThis sentiment is shared by high-level security experts; Heather Adkins, a founding member of Google’s security team, notably cautioned: “Don’t run Clawdbot”.\nThe technology: real-time blocking and ToolGuard\nRunlayer’s ToolGuard technology attempts to solve this by introducing real-time blocking with a latency of less than 100ms. \nBy analyzing tool execution outputs before they are finalized, the system can catch remote code execution patterns, such as \"curl | bash\" or destructive \"rm -rf\" commands, that typically bypass traditional filters. \nAccording to Runlayer's internal benchmarks, this technical layer increases prompt injection resistance from a baseline of 8.7% to 95%.\nThe Runlayer suite for OpenClaw is structured around two primary pillars: discovery and active defense.\n\nOpenClaw Watch: This tool functions as a detection mechanism for \"shadow\" Model Context Protocol (MCP) servers across an organization. It can be deployed via Mobile Device Management (MDM) software to scan employee devices for unmanaged configurations.\n\nRunlayer ToolGuard: This is the active enforcement engine that monitors every tool call made by the agent,. It is designed to catch over 90% of credential exfiltration attempts, specifically looking for the \"leaking\" of AWS keys, database credentials, and Slack tokens.\n\nBerman noted in our interview that the goal is to provide the infrastructure to govern AI agents \"in the same way that the enterprise learned to govern the cloud, to govern SaaS, to govern mobile\". \nUnlike standard LLM gateways or MCP proxies, Runlayer provides a control plane that integrates directly with existing enterprise identity providers (IDPs) like Okta and Entra.\nLicensing, privacy, and the security vendor model\nWhile the OpenClaw community often relies on open-source or unmanaged scripts, Runlayer positions its enterprise solution as a proprietary commercial layer designed to meet rigorous standards. The platform is SOC 2 certified and HIPAA certified, making it a viable option for companies in highly regulated sectors.\nBerman clarified the company's approach to data in the interview, stating: \"Our ToolGuard model family... these are all focused on the security risks with these type of tools, and we don't train on organizations' data\". He further emphasized that contracting with Runlayer \"looks exactly like you're contracting with a security vendor,\" rather than an LLM inference provider. \nThis distinction is critical; it means any data used is anonymized at the source, and the platform does not rely on inference to provide its security layers.\nFor the end-user, this licensing model means a transition from \"community-supported\" risk to \"enterprise-supported\" stability. While the underlying AI agent might be flexible and experimental, the Runlayer wrapper provides the legal and technical guarantees—such as terms of service and privacy policies—that large organizations require.\nPricing and organizational deployment\nRunlayer’s pricing structure deviates from the traditional per-user seat model common in SaaS. Berman explained in our interview that the company prefers a platform fee to encourage wide-scale adoption without the friction of incremental costs: \"We don't believe in charging per user. We want you to roll it enterprise across your organization\".\nThis platform fee is scoped based on the size of the deployment and the specific capabilities the customer requires.\nBecause Runlayer functions as a comprehensive control plane—offering \"six products on day one\"—the pricing is tailored to the infrastructure needs of the enterprise rather than simple headcount. \nRunlayer's current focus is on enterprise and mid-market segments, but Berman noted that the company plans to introduce offerings in the future specifically \"scoped to smaller companies\".\nIntegration: from IT to AI transformation\nRunlayer is designed to fit into the existing \"stack\" used by security and infrastructure teams. For engineering and IT teams, it can be deployed in the cloud, within a private virtual private cloud (VPC), or even on-premise. Every tool call is logged and auditable, with integrations that allow data to be exported to SIEM vendors like Datadog or Splunk.\nDuring our interview, Berman highlighted the positive cultural shift that occurs when these tools are secured properly, rather than banned. He cited the example of Gusto, where the IT team was renamed the \"AI transformation team\" after partnering with Runlayer. \nBerman said: \"We have taken their company from... not using these type of tools, to half the company on a daily basis using MCP, and it’s incredible\". He noted that this includes non-technical users, proving that safe AI adoption can scale across an entire workforce.\nSimilarly, Berman shared a quote from a customer at home sales tech firm OpenDoor who claimed that \"hands down, the biggest quality of life improvement I'm noticing at OpenDoor is Runlayer\" because it allowed them to connect agents to sensitive, private systems without fear of compromise.\nThe path forward for agentic AI\nThe market response appears to validate the need for this \"middle ground\" in AI governance. Runlayer already powers security for several high-growth companies, including Gusto, Instacart, Homebase, and AngelList. \nThese early adopters suggest that the future of AI in the workplace may not be found in banning powerful tools, but in wrapping them in a layer of measurable, real-time governance.\nAs the cost of tokens drops and the capabilities of models like \"Opus 4.5\" or \"GPT 5.2\" increase, the urgency for this infrastructure only grows. \n\"The question isn't really whether enterprise will use agents,\" Berman concluded in our interview, \"it's whether they can do it, how fast they can do it safely, or they're going to just do it recklessly, and it's going to be a disaster\". \nFor the modern CISO, the goal is no longer to be the person who says \"no,\" but to be the enabler who brings a \"governed, safe, and secure way to roll out AI\".",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Runlayer has launched 'OpenClaw for Enterprise,' a governance solution for the OpenClaw AI agent, which has gained popularity for its automation capabilities. With OpenClaw often operating with root-level access, security risks have surged, prompting IT departments to struggle against unmanaged AI. Runlayer's ToolGuard technology increases prompt injection resistance from 8.7% to 95%, addressing these vulnerabilities. This development is crucial as businesses seek to adopt AI while maintaining security and compliance.",
  "why_it_matters": [
    "Businesses using OpenClaw could now implement safer AI solutions, reducing risks of data breaches and unauthorized access.",
    "The launch signals a broader trend towards integrating AI governance in corporate environments, emphasizing safety alongside innovation."
  ],
  "lenses": {
    "eli12": "Runlayer's new tool helps companies use AI agents like OpenClaw safely. Think of it like adding a security system to a smart home; it keeps everything secure while still letting you enjoy the benefits. This matters because it allows everyday workers to harness AI's power without compromising their data.",
    "pm": "For product managers, Runlayer's solution addresses a key user need: safe AI usage in the workplace. By providing a governance layer, it could enhance efficiency without the risks traditionally tied to AI tools. This means teams can focus on innovation rather than constantly worrying about security breaches.",
    "engineer": "From a technical standpoint, Runlayer's ToolGuard enhances security by monitoring tool execution in real-time, increasing prompt injection resistance significantly. The system can detect harmful command patterns, which is crucial given OpenClaw's architecture that allows root-level access. This approach could redefine how enterprises manage AI tools, balancing functionality with necessary security measures."
  },
  "hype_meter": 4,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2026-02-23T05:15:44.458Z",
  "updated_at": "2026-02-23T05:15:44.459Z",
  "processing_order": 1771823744460
}