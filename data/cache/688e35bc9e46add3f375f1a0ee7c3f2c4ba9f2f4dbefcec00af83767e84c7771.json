{
  "content_hash": "688e35bc9e46add3f375f1a0ee7c3f2c4ba9f2f4dbefcec00af83767e84c7771",
  "title": "Estimating worst case frontier risks of open weight LLMs",
  "url": "https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms",
  "source": "OpenAI",
  "published_at": "2025-08-05T00:00:00.000Z",
  "raw_excerpt": "In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity.",
  "raw_body": "In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "The paper examines risks of malicious fine-tuning in open weight LLMs like gpt-oss.",
  "why_it_matters": [
    "Identifies potential dangers of advanced AI capabilities.",
    "Highlights the need for responsible AI release practices."
  ],
  "lenses": {
    "eli12": "This study looks at risks from powerful AI models. It focuses on how bad people could misuse them.",
    "pm": "Users of LLMs include researchers and developers. The market is growing, but risks like misuse could hinder adoption.",
    "engineer": "The method involves fine-tuning LLMs for specific tasks. Data constraints include ethical considerations and potential misuse limits."
  },
  "hype_meter": 3,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v1.0"
  },
  "created_at": "2025-08-11T18:10:15.087Z",
  "updated_at": "2025-08-11T18:10:15.087Z"
}