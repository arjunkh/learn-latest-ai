{
  "content_hash": "004f5183c93be9fcab0329aac3b7cf4f9704ad88fe72c887472febfcdf622f40",
  "share_id": "ciabl5",
  "title": "Cognitive Inception: Agentic Reasoning against Visual Deceptions by Injecting Skepticism",
  "optimized_headline": "Unlocking Agentic Reasoning: How Skepticism Defeats Visual Deceptions",
  "url": "https://arxiv.org/abs/2511.17672",
  "source": "ArXiv AI",
  "published_at": "2025-11-26T05:00:00.000Z",
  "raw_excerpt": "arXiv:2511.17672v1 Announce Type: new \nAbstract: As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by generated contents, and the reliability of reasoning processes is jeopardized. Therefore, facing rap",
  "raw_body": "arXiv:2511.17672v1 Announce Type: new \nAbstract: As the development of AI-generated contents (AIGC), multi-modal Large Language Models (LLM) struggle to identify generated visual inputs from real ones. Such shortcoming causes vulnerability against visual deceptions, where the models are deceived by generated contents, and the reliability of reasoning processes is jeopardized. Therefore, facing rapidly emerging generative models and diverse data distribution, it is of vital importance to improve LLMs' generalizable reasoning to verify the authenticity of visual inputs against potential deceptions. Inspired by human cognitive processes, we discovered that LLMs exhibit tendency of over-trusting the visual inputs, while injecting skepticism could significantly improve the models visual cognitive capability against visual deceptions. Based on this discovery, we propose \\textbf{Inception}, a fully reasoning-based agentic reasoning framework to conduct generalizable authenticity verification by injecting skepticism, where LLMs' reasoning logic is iteratively enhanced between External Skeptic and Internal Skeptic agents. To the best of our knowledge, this is the first fully reasoning-based framework against AIGC visual deceptions. Our approach achieved a large margin of performance improvement over the strongest existing LLM baselines and SOTA performance on AEGIS benchmark.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "A new framework called Inception has been proposed to help large language models (LLMs) better identify real versus AI-generated visual content. Current LLMs often over-trust visual inputs, making them susceptible to deception. By injecting skepticism into their reasoning processes, Inception significantly enhances their ability to verify authenticity. This matters now as the rise of AI-generated content poses increasing challenges to the reliability of AI systems.",
  "why_it_matters": [
    "This framework could help developers create more trustworthy AI systems, benefiting industries relying on visual data verification.",
    "It signals a shift towards more robust AI models that can better navigate the complexities of AI-generated content, influencing future AI research and applications."
  ],
  "lenses": {
    "eli12": "Imagine if your friend always believed everything they saw online, even if it was fake. Inception teaches AI to be more skeptical about visuals, improving how it understands what's real. This is important for everyone because it could lead to more reliable AI tools in daily life, like better image recognition apps.",
    "pm": "For product managers, Inception offers a way to enhance user trust in AI systems by ensuring they can accurately differentiate between real and generated content. This could lead to lower costs related to misinformation and enhance user experience. Implementing this framework might also provide a competitive edge in markets increasingly reliant on visual data.",
    "engineer": "Inception introduces a reasoning-based framework that enhances LLMs' visual cognitive capabilities by using External and Internal Skeptic agents. This approach achieved significant performance improvements over current LLM baselines and reached state-of-the-art results on the AEGIS benchmark. Its innovative method of injecting skepticism could reshape how models handle visual deceptions."
  },
  "hype_meter": 2,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-11-27T03:55:36.907Z",
  "updated_at": "2025-11-27T03:55:36.907Z",
  "processing_order": 1764215736910
}