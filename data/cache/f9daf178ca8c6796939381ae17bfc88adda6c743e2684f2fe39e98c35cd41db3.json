{
  "content_hash": "f9daf178ca8c6796939381ae17bfc88adda6c743e2684f2fe39e98c35cd41db3",
  "share_id": "flikrz",
  "title": "From logs to insights: The AI breakthrough redefining observability",
  "optimized_headline": "AI Breakthrough Transforms Log Data into Actionable Insights for Observability",
  "url": "https://venturebeat.com/ai/from-logs-to-insights-the-ai-breakthrough-redefining-observability",
  "source": "VentureBeat",
  "published_at": "2025-11-05T05:00:00.000Z",
  "raw_excerpt": "Presented by Elastic \n\nLogs set to become the primary tool for finding the “why” in diagnosing network incidents \nModern IT environments have a data problem: there’s too much of it. Organizations that need to manage a company’s environment are increasingly challenged to detect and diagnose issues in real-time, optimize performance, improve reliability, and ensure security and compliance — all with",
  "raw_body": "Presented by Elastic \n\nLogs set to become the primary tool for finding the “why” in diagnosing network incidents \nModern IT environments have a data problem: there’s too much of it. Organizations that need to manage a company’s environment are increasingly challenged to detect and diagnose issues in real-time, optimize performance, improve reliability, and ensure security and compliance — all within constrained budgets. \nThe modern observability landscape has many tools that offer a solution. Most revolve around DevOps teams or Site Reliability Engineers (SREs) analyzing logs, metrics, and traces to uncover patterns and figure out what’s happening across the network, and diagnose why an issue or incident occurred. The problem is that the process creates information overload: A Kubernetes cluster alone can emit 30 to 50 gigabytes of logs a day, and suspicious behavior patterns can sneak past human eyes. \n\"It’s so anachronistic now, in the world of AI, to think about humans alone observing infrastructure,\" says Ken Exner, chief product officer at Elastic. \"I hate to break it to you, but machines are better than human beings at pattern matching.“\nAn industry-wide focus on visualizing symptoms forces engineers to manually hunt for answers. The crucial \"why\" is buried in logs, but because they contain massive volumes of unstructured data, the industry tends to use them as a tool of last resort. This has forced teams into costly tradeoffs: either spend countless hours building complex data pipelines, drop valuable log data and risk critical visibility gaps, or log and forget.\nElastic, the Search AI Company, recently released a new feature for observability called Streams, which aims to become the primary signal for investigations by taking noisy logs and turning them into patterns, context and meaning. \nStreams uses AI to automatically partition and parse raw logs to extract relevant fields, and greatly reduce the effort required of SREs to make logs usable. Streams also automatically surfaces significant events such as critical errors and anomalies from context-rich logs, giving SREs early warnings and a clear understanding of their workloads, enabling them to investigate and resolve issues faster. The ultimate goal is to show remediation steps.\n\"From raw, voluminous, messy data, Streams automatically creates structure, putting it into a form that is usable, automatically alerts you to issues and helps you remediate them,\" Exner says. \"That is the magic of Streams.\"\nA broken workflow\nStreams upends an observability process that some say is broken. Typically, SREs set up metrics, logs and traces. Then they set up alerts, and service level objectives (SLOs) — often hard-coded rules to show where a service or process has gone beyond a threshold, or a specific pattern has been detected. \nWhen an alert is triggered, it points to the metric that's showing an anomaly. From there, SREs look at a metrics dashboard, where they can visualize the issue and compare the alert to other metrics, or CPU to memory to I/O, and start looking for patterns. \nThey may then need to look at a trace, and examine upstream and downstream dependencies across the application to dig into the root cause of the issue. Once they figure out what's causing the trouble, they jump into the logs for that database or service to try and debug the issue. \nSome companies simply seek to add more tools when current ones prove ineffective. That means SREs are hopping from tool to tool to keep on top of monitoring and troubleshooting across their infrastructure and applications.\n\"You’re hopping across different tools. You’re relying on a human to interpret these things, visually look at the relationship between systems in a service map, visually look at graphs on a metrics dashboard, to figure out what and where the issue is, \" Exner says. \"But AI automates that workflow away.\" \nWith AI-powered Streams, logs are not just used reactively to resolve issues, but also to proactively process potential issues and create information-rich alerts that help teams jump straight to problem-solving, offering a solution for remediation or even fixing the issue entirely, before automatically notifying the team that it's been taken care of.\n\"I believe that logs, the richest set of information, the original signal type, will start driving a lot of the automation that a service reliability engineer typically does today, and does very manually,\" he adds. \"A human should not be in that process, where they are doing this by digging into themselves, trying to figure out what is going on, where and what the issue is, and then once they find the root cause, they’re trying to figure out how to debug it.\"\nObservability’s future \nLarge language models (LLMs) could be a key player in the future of observability. LLMs excel at recognizing patterns in vast quantities of repetitive data, which closely resembles log and telemetry data in complex, dynamic systems. And today’s LLMs can be trained for specific IT processes. With automation tooling, the LLM has the information and tools it needs to resolve database errors or Java heap issues, and more. Incorporating those into platforms that bring context and relevance will be essential. \nAutomated remediation will still take some time, Exner says, but automated runbooks and playbooks generated by LLMs will become standard practice within the next couple of years. In other words, remediation steps will be driven by LLMs. The LLM will offer up fixes, and the human will verify and implement them, rather than calling in an expert.\nAddressing skill shortages\nGoing all in on AI for observability would help address a major shortage in the talent needed to manage IT infrastructure. Hiring is slow because organizations need teams with a great deal of experience and understanding of potential issues, and how to resolve them fast. That experience can come from an LLM that is contextually grounded, Exner says.\n\"We can help deal with the skill shortage by augmenting people with LLMs that make them all instantly experts,\" he explains. \"I think this is going to make it much easier for us to take novice practitioners and make them expert practitioners in both security and observability, and it’s going to make it possible for a more novice practitioner to act like an expert.” \nStreams in Elastic Observability is available now. Get started by reading more on the Streams. \n\nSponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
  "category": "capabilities_and_how",
  "category_confidence": "medium",
  "speedrun": "Elastic has introduced a new feature called Streams, which transforms noisy logs into meaningful patterns, aiding in real-time network incident diagnosis. By using AI to automatically parse and analyze logs, Streams reduces the effort required from Site Reliability Engineers (SREs) and surfaces critical alerts. This shift from reactive to proactive log management could enhance performance and reliability in IT environments. As organizations face increasing data volumes, this innovation matters now for improving operational efficiency.",
  "why_it_matters": [
    "SREs can diagnose issues faster, reducing downtime and improving service reliability through automated insights from logs.",
    "This development indicates a broader shift towards AI-driven solutions in IT, addressing the growing complexity of modern infrastructures."
  ],
  "lenses": {
    "eli12": "Elastic's new Streams feature is like turning a messy pile of papers into a well-organized filing system. Instead of sifting through heaps of unstructured logs, SREs can now easily find relevant information and get alerts about issues. This matters for everyday people because smoother IT operations lead to more reliable services and fewer disruptions in their digital experiences.",
    "pm": "For product managers and founders, Streams addresses a critical user need by simplifying log analysis, which can save time and resources. By automating the detection of issues, teams could allocate their efforts towards innovation rather than troubleshooting. This not only enhances efficiency but could also lead to better product reliability and customer satisfaction.",
    "engineer": "From a technical perspective, Streams leverages AI to automatically partition and parse logs, which could significantly reduce the manual effort required by SREs. By surfacing critical events and anomalies from complex log data, it streamlines the observability process. This approach could enhance the ability to diagnose issues quickly, ultimately driving improvements in system reliability and performance."
  },
  "hype_meter": 5,
  "model_meta": {
    "model": "gpt-4o-mini",
    "prompt_version": "v2.1"
  },
  "created_at": "2025-11-06T04:00:42.303Z",
  "updated_at": "2025-11-06T04:00:42.303Z",
  "processing_order": 1762401642305
}